{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YairZen/CloudProject_Unicorn/blob/lior/HW3_Unicorn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxU3y_ahSBCr"
      },
      "source": [
        "‚úÖ PIP INSTALL (GLOBAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QD6QB2FYWlkD"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade gradio pandas matplotlib python-docx\n",
        "!pip install -q --upgrade firebase-admin plotly gdown\n",
        "!pip -q install cerebras-cloud-sdk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXiHxUFpa556"
      },
      "source": [
        "‚úÖ IMPORTS (GLOBAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkZpGdnxM6az"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "import requests\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#######\n",
        "# Report Generator with DOCX Export\n",
        "from cerebras.cloud.sdk import Cerebras\n",
        "from zoneinfo import ZoneInfo\n",
        "from datetime import timezone\n",
        "from docx import Document\n",
        "import tempfile\n",
        "import os\n",
        "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
        "from docx.shared import Inches, Pt, RGBColor\n",
        "from datetime import datetime, timedelta\n",
        "from typing import List, Dict\n",
        "\n",
        "#Gamification imports\n",
        "import random\n",
        "\n",
        "# Firebase imports\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, db\n",
        "\n",
        "# Additional imports for IoT Dashboard\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "from datetime import timedelta\n",
        "import gdown\n",
        "import json\n",
        "\n",
        "# Plotly imports\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import numpy as np\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#--------RAG & Index-------------#\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from urllib.parse import quote\n",
        "\n",
        "# --- Web fetch + HTML parsing ---\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# --- NLP (stemming / stopwords) ---\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSPgJzDMOn_M"
      },
      "source": [
        "Firebase & API Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGLzSlUNOmJ0"
      },
      "outputs": [],
      "source": [
        "#CEREBRAS cardetntial\n",
        "os.environ[\"CEREBRAS_API_KEY\"] =\"csk-r8npfcy9jckcxcd98t4422mw99wx3ew89k4h3rrhdvy5ekde\"\n",
        "client = Cerebras(api_key=os.environ[\"CEREBRAS_API_KEY\"])\n",
        "REPORT_MODEL_NAME = \"llama3.1-8b\"\n",
        "\n",
        "# Firebase credentials\n",
        "FIREBASE_KEY_ID = '1ESnh8BIbGKrVEijA9nKNgNJNdD5kAaYC'\n",
        "firebase_key_file = 'firebase_key.json'\n",
        "#add for the RAG & INDEX CODE#\n",
        "FIREBASE_URL = \"https://cloud-81451-default-rtdb.europe-west1.firebasedatabase.app/\"\n",
        "#-----#\n",
        "if os.path.exists(firebase_key_file):\n",
        "    os.remove(firebase_key_file)\n",
        "\n",
        "print(' Downloading Firebase credentials...')\n",
        "try:\n",
        "    url = f'https://drive.google.com/uc?id={FIREBASE_KEY_ID}'\n",
        "    gdown.download(url, firebase_key_file, quiet=False, fuzzy=True)\n",
        "    with open(firebase_key_file, 'r') as f:\n",
        "        creds = json.load(f)\n",
        "    print(f'‚úì Project: {creds.get(\"project_id\")}')\n",
        "except Exception as e:\n",
        "    print(f'‚ö†Ô∏è Error: {e}')\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        os.rename(list(uploaded.keys())[0], firebase_key_file)\n",
        "\n",
        "# Initialize Firebase\n",
        "if not firebase_admin._apps:\n",
        "    firebase_admin.initialize_app(\n",
        "        credentials.Certificate(firebase_key_file),\n",
        "        {'databaseURL': 'https://cloud-81451-default-rtdb.europe-west1.firebasedatabase.app/'}\n",
        "    )\n",
        "    print(' Firebase initialized')\n",
        "\n",
        "# Server Configuration (already exists in Cell 6, but adding here for completeness)\n",
        "BATCH_LIMIT = 200\n",
        "\n",
        "print(' Firebase configured')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3VvQJgmOu6H"
      },
      "source": [
        "## üîÑ Firebase Sync Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXeOpqeCOwvs"
      },
      "outputs": [],
      "source": [
        "# Sync Functions\n",
        "\n",
        "def get_latest_timestamp_from_firebase():\n",
        "    try:\n",
        "        latest = db.reference('/sensor_data').order_by_child('created_at').limit_to_last(1).get()\n",
        "        return list(latest.values())[0]['created_at'] if latest else None\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def fetch_batch_from_server(before_timestamp=None):\n",
        "    params = {\"feed\": FEED, \"limit\": BATCH_LIMIT}\n",
        "    if before_timestamp:\n",
        "        params[\"before_created_at\"] = before_timestamp\n",
        "    try:\n",
        "        return requests.get(f\"{BASE_URL}/history\", params=params, timeout=180).json()\n",
        "    except:\n",
        "        return {}\n",
        "\n",
        "def save_sensor_data_to_firebase(data_list):\n",
        "    if not data_list:\n",
        "        return 0\n",
        "\n",
        "    ref = db.reference('/sensor_data')\n",
        "    saved = 0\n",
        "\n",
        "    for sample in data_list:\n",
        "        try:\n",
        "            vals = json.loads(sample['value'])\n",
        "            temperature = max(-50, min(100, float(vals['temperature'])))\n",
        "            humidity = max(0, min(100, float(vals['humidity'])))\n",
        "            soil = max(0, min(100, float(vals['soil'])))\n",
        "            timestamp_key = sample['created_at'].replace(':', '-').replace('.', '-')\n",
        "\n",
        "            ref.child(timestamp_key).set({\n",
        "                'created_at': sample['created_at'],\n",
        "                'temperature': temperature,\n",
        "                'humidity': humidity,\n",
        "                'soil': soil\n",
        "            })\n",
        "\n",
        "            saved += 1\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    return saved\n",
        "\n",
        "def sync_new_data_from_server():\n",
        "    msgs = [\"Starting sync...\"]\n",
        "    latest = get_latest_timestamp_from_firebase()\n",
        "    msgs.append(f\"Latest: {latest}\" if latest else \"No existing data\")\n",
        "    resp = fetch_batch_from_server()\n",
        "\n",
        "    if \"data\" not in resp:\n",
        "        return \"\\n\".join(msgs + [\"Error fetching data\"]), 0\n",
        "\n",
        "    new = [s for s in resp[\"data\"] if not latest or s[\"created_at\"] > latest]\n",
        "\n",
        "    if new:\n",
        "        saved = save_sensor_data_to_firebase(new)\n",
        "        return \"\\n\".join(msgs + [f\"Found {len(new)} new\", f\"Saved {saved}!\"]), saved\n",
        "\n",
        "    return \"\\n\".join(msgs + [\"No new data\"]), 0\n",
        "\n",
        "print('Sync functions loaded')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_Vu19SqO2Ic"
      },
      "source": [
        "## üìä Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdmkuJAZO3iv"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# Data Loading (YOUR ORIGINAL CODE)\n",
        "\n",
        "def load_data_from_firebase():\n",
        "    data = db.reference('/sensor_data').get()\n",
        "    if not data:\n",
        "        return pd.DataFrame()\n",
        "    df = pd.DataFrame([{\n",
        "        'timestamp': pd.to_datetime(v['created_at']),\n",
        "        'temperature': float(v['temperature']),\n",
        "        'humidity': float(v['humidity']),\n",
        "        'soil': float(v['soil'])\n",
        "    } for v in data.values()])\n",
        "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "    df['humidity'] = df['humidity'].clip(0, 100)\n",
        "    df['soil'] = df['soil'].clip(0, 100)\n",
        "    df['temperature'] = df['temperature'].clip(-50, 100)\n",
        "    return df\n",
        "\n",
        "print('‚úÖ Data loading ready')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJqc9RlyNbcN"
      },
      "source": [
        "‚úÖ GLOBAL CONFIG / THEME / CSS (OPTIONAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zz7Tm5DJM7hn"
      },
      "outputs": [],
      "source": [
        "# Global Configuration\n",
        "\n",
        "# ============================================================================\n",
        "# SERVER & FEED CONFIGURATION (YOUR ORIGINAL SETTINGS)\n",
        "# ============================================================================\n",
        "FEED = \"json\"  # Your feed name - CHANGE THIS if different\n",
        "BASE_URL = \"https://server-cloud-v645.onrender.com/\"\n",
        "BATCH_LIMIT = 200\n",
        "\n",
        "# ============================================================================\n",
        "# APP CONFIGURATION\n",
        "# ============================================================================\n",
        "APP_TITLE = \"üå± CloudGarden\"\n",
        "APP_SUBTITLE = \"Smart Plant Disease Detection System\"\n",
        "\n",
        "# --- Colors for Friend's Realtime Dashboard ---\n",
        "COLOR_TEMP = \"#1f77b4\"   # blue\n",
        "COLOR_HUM  = \"#ff7f0e\"   # orange\n",
        "COLOR_SOIL = \"#2ca02c\"   # green\n",
        "\n",
        "STATUS_OK_COLOR = \"#2ca02c\"      # green\n",
        "STATUS_WARN_COLOR = \"#ffbf00\"    # yellow\n",
        "STATUS_BAD_COLOR = \"#d62728\"     # red\n",
        "\n",
        "# --- ML Model Configuration ---\n",
        "MODEL_NAME = \"linkanjarad/mobilenet_v2_1.0_224-plant-disease-identification\"\n",
        "clf = pipeline(\"image-classification\", model=MODEL_NAME)\n",
        "\n",
        "# ============================================================================\n",
        "# CSS STYLING FOR IOT DASHBOARD\n",
        "# ============================================================================\n",
        "\n",
        "COLORS = {\n",
        "    'temperature': {'color': '#ef4444'},\n",
        "    'humidity': {'color': '#3b82f6'},\n",
        "    'soil': {'color': '#8b5cf6'}\n",
        "}\n",
        "\n",
        "CUSTOM_CSS = \"\"\"\n",
        "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');\n",
        "* { font-family: 'Inter', sans-serif; }\n",
        "\n",
        ".kpi-card {\n",
        "    background: white;\n",
        "    padding: 24px;\n",
        "    border-radius: 12px;\n",
        "    box-shadow: 0 1px 3px rgba(0,0,0,0.12);\n",
        "    text-align: center;\n",
        "    border-left: 4px solid;\n",
        "}\n",
        ".kpi-label { color: #6b7280; font-size: 14px; font-weight: 600; }\n",
        ".kpi-value { font-size: 48px; font-weight: 700; color: #1f2937; }\n",
        ".trend-up { color: #10b981; }\n",
        ".trend-down { color: #ef4444; }\n",
        "\n",
        "/* Tooltip styles */\n",
        ".info-icon {\n",
        "    position: relative;\n",
        "    display: inline-flex;\n",
        "    cursor: help;\n",
        "}\n",
        "\n",
        ".info-icon .tooltip-text {\n",
        "    visibility: hidden;\n",
        "    width: 200px;\n",
        "    background-color: #1f2937;\n",
        "    color: white;\n",
        "    text-align: center;\n",
        "    border-radius: 6px;\n",
        "    padding: 8px;\n",
        "    position: absolute;\n",
        "    z-index: 1000;\n",
        "    bottom: 125%;\n",
        "    left: 50%;\n",
        "    margin-left: -100px;\n",
        "    opacity: 0;\n",
        "    transition: opacity 0.3s;\n",
        "    font-size: 11px;\n",
        "    line-height: 1.4;\n",
        "    box-shadow: 0 2px 8px rgba(0,0,0,0.2);\n",
        "}\n",
        "\n",
        ".info-icon .tooltip-text::after {\n",
        "    content: \"\";\n",
        "    position: absolute;\n",
        "    top: 100%;\n",
        "    left: 50%;\n",
        "    margin-left: -5px;\n",
        "    border-width: 5px;\n",
        "    border-style: solid;\n",
        "    border-color: #1f2937 transparent transparent transparent;\n",
        "}\n",
        "\n",
        ".info-icon:hover .tooltip-text {\n",
        "    visibility: visible;\n",
        "    opacity: 1;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "print('‚úÖ Configuration loaded')\n",
        "print(f'üì° Server: {BASE_URL}')\n",
        "print(f'üìª Feed: {FEED}')\n",
        "print(f'üì¶ Batch limit: {BATCH_LIMIT}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISU3vcbDNf1p"
      },
      "source": [
        "‚úÖ TAB REGISTRY (MODULAR)\n",
        "\n",
        " ◊û◊ï◊°◊ô◊§◊ô◊ù ◊ó◊ú◊ï◊†◊ô◊™ ◊ó◊ì◊©◊î ◊®◊ß ◊¢\"◊ô:\n",
        " 1) ◊î◊ï◊°◊§◊™ TAB1 Logic - ◊õ◊ú ◊î◊§◊ï◊†◊ß◊¶◊ô◊ï◊™ ◊¢◊ñ◊® ◊ú◊û◊ô◊†◊î◊ù.\n",
        " 2) ◊î◊ï◊°◊§◊™ Tab1 GUI - ◊õ◊ú GRADIO\n",
        " * ◊ô◊© ◊ú◊î◊ï◊®◊ô◊ì ◊ê◊™ \"with gr.Blocks() as demo:\" ◊ï \"demo.launch()\"\n",
        "\n",
        " 3) ◊ú◊î◊ï◊°◊ô◊£ ◊ê◊™ ◊©◊ù ◊î◊§◊ï◊†◊ß◊¶◊ô◊ô◊™ GUI ◊ú◊®◊©◊ô◊û◊™ ◊îTAB ◊ú◊û◊ò◊î."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNQNqiEsWqfZ"
      },
      "source": [
        "‚úÖ TAB 1 Logic -  üå± Realtime Dashboard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNh-iF2WWqLB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---------- Core Data Fetch ----------\n",
        "def load_iot_data(feed: str, limit: int) -> pd.DataFrame | None:\n",
        "    resp = requests.get(\n",
        "        f\"{BASE_URL}/history\",\n",
        "        params={\"feed\": feed, \"limit\": limit},\n",
        "        timeout=30\n",
        "    )\n",
        "    data = resp.json()\n",
        "    if \"data\" not in data or not data[\"data\"]:\n",
        "        return None\n",
        "\n",
        "    df = pd.DataFrame(data[\"data\"])\n",
        "    if \"created_at\" not in df.columns or \"value\" not in df.columns:\n",
        "        return None\n",
        "\n",
        "    df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], errors=\"coerce\", utc=True)\n",
        "    df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"created_at\", \"value\"]).sort_values(\"created_at\")\n",
        "\n",
        "    return None if df.empty else df\n",
        "\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def normalize(series: pd.Series) -> pd.Series:\n",
        "    mn, mx = float(series.min()), float(series.max())\n",
        "    if mx - mn == 0:\n",
        "        return series * 0.0\n",
        "    return (series - mn) / (mx - mn)\n",
        "\n",
        "\n",
        "# ---------- Plant Status + Plots ----------\n",
        "def plant_dashboard(limit: int):\n",
        "    try:\n",
        "        dfs = {\n",
        "            \"temperature\": load_iot_data(\"temperature\", limit),\n",
        "            \"humidity\": load_iot_data(\"humidity\", limit),\n",
        "            \"soil\": load_iot_data(\"soil\", limit),\n",
        "        }\n",
        "\n",
        "        missing = [k for k, v in dfs.items() if v is None]\n",
        "        if missing:\n",
        "            return \"‚ö†Ô∏è Partial Data\", f\"Missing sensors or empty history: {', '.join(missing)}\", None, None, None, None\n",
        "\n",
        "        temp = float(dfs[\"temperature\"][\"value\"].iloc[-1])\n",
        "        hum = float(dfs[\"humidity\"][\"value\"].iloc[-1])\n",
        "        soil = float(dfs[\"soil\"][\"value\"].iloc[-1])\n",
        "\n",
        "        issues, warnings = [], []\n",
        "\n",
        "        checks = [\n",
        "            (\"Temperature\", temp, 18, 32, 1),\n",
        "            (\"Air humidity\", hum, 35, 75, 3),\n",
        "            (\"Soil moisture\", soil, 20, 60, 3),\n",
        "        ]\n",
        "\n",
        "        for name, value, low, high, margin in checks:\n",
        "            if not (low <= value <= high):\n",
        "                issues.append(f\"{name} out of range ({value:.1f})\")\n",
        "            elif value <= low + margin or value >= high - margin:\n",
        "                warnings.append(f\"{name} near limit ({value:.1f})\")\n",
        "\n",
        "        if issues:\n",
        "            status = \"üî¥ Plant Status: Not OK\"\n",
        "            details_main = \" ; \".join(issues)\n",
        "\n",
        "        elif warnings:\n",
        "            status = \"üü° Plant Status: Warning\"\n",
        "            details_main = \" ; \".join(warnings)\n",
        "\n",
        "        else:\n",
        "            status = \"üü¢ Plant Status: OK\"\n",
        "            details_main = \"All sensors are within valid ranges\"\n",
        "\n",
        "        details = (\n",
        "    f\"{details_main}\\n\"\n",
        "    f\"Latest values:\\n\"\n",
        "    f\"temp={temp:.1f}\\n\"\n",
        "    f\"humidity={hum:.1f}\\n\"\n",
        "    f\"soil={soil:.1f}\"\n",
        "\n",
        "        )\n",
        "\n",
        "        df_t, df_h, df_s = dfs[\"temperature\"], dfs[\"humidity\"], dfs[\"soil\"]\n",
        "\n",
        "        fig_t = plt.figure(figsize=(7, 3.2))\n",
        "        plt.plot(df_t[\"created_at\"], df_t[\"value\"], marker=\"o\", color=COLOR_TEMP)\n",
        "        plt.title(\"Temperature History\")\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"¬∞C\")\n",
        "        plt.grid(True)\n",
        "\n",
        "        fig_h = plt.figure(figsize=(7, 3.2))\n",
        "        plt.plot(df_h[\"created_at\"], df_h[\"value\"], marker=\"o\", color=COLOR_HUM)\n",
        "        plt.title(\"Air Humidity History\")\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"%\")\n",
        "        plt.grid(True)\n",
        "\n",
        "        fig_s = plt.figure(figsize=(7, 3.2))\n",
        "        plt.plot(df_s[\"created_at\"], df_s[\"value\"], marker=\"o\", color=COLOR_SOIL)\n",
        "        plt.title(\"Soil Moisture History\")\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"%\")\n",
        "        plt.grid(True)\n",
        "\n",
        "        fig_c = plt.figure(figsize=(10, 3.4))\n",
        "        plt.plot(df_t[\"created_at\"], normalize(df_t[\"value\"]), marker=\"o\", label=\"Temperature (norm)\", color=COLOR_TEMP)\n",
        "        plt.plot(df_h[\"created_at\"], normalize(df_h[\"value\"]), marker=\"o\", label=\"Humidity (norm)\", color=COLOR_HUM)\n",
        "        plt.plot(df_s[\"created_at\"], normalize(df_s[\"value\"]), marker=\"o\", label=\"Soil (norm)\", color=COLOR_SOIL)\n",
        "        plt.title(\"Combined Trend (Normalized)\")\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"Normalized Value (0‚Äì1)\")\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "\n",
        "        return status, details, fig_t, fig_h, fig_s, fig_c\n",
        "\n",
        "    except Exception:\n",
        "        return \"‚ùå Error\", \"Failed to fetch data from server. Please try again.\", None, None, None, None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbBhAJeHXGSH"
      },
      "source": [
        "‚úÖ Tab 1 GUI - - üå± Realtime Dashboard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mw1loVKKYxN0"
      },
      "outputs": [],
      "source": [
        "def build_realtime_dashboard_tab():\n",
        "    gr.Markdown(\n",
        "    \"<h3 style='margin:0; font-size:22px;'>üåø Overall Plant Status (Real-Time)</h3>\"\n",
        ")\n",
        "\n",
        "\n",
        "    samples = gr.Slider(1, 200, value=20, step=1, label=\"Number of Samples (used for all graphs)\")\n",
        "    overall_btn = gr.Button(\"Update Plant Dashboard\", variant=\"primary\")\n",
        "\n",
        "\n",
        "\n",
        "    overall_status = gr.Textbox(\n",
        "        label=\"Overall Status\",\n",
        "        lines=1,\n",
        "        placeholder=\"Click 'Update Plant Dashboard' to evaluate plant status\"\n",
        "    )\n",
        "    overall_info = gr.Textbox(\n",
        "        label=\"Status Details\",\n",
        "        lines=4,\n",
        "        placeholder=\"Detailed plant analysis will appear here\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        gr.Markdown(f\"\"\"\n",
        "<div class=\"legend-card\" style=\"margin-top:14px;padding:14px;border:1px solid var(--border-color-primary)\n",
        ";border-radius:10px;\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  <h4 style=\"margin-bottom:10px; font-size:20px; font-weight:600;\">\n",
        "üåø Plant Status\n",
        "</h4>\n",
        "\n",
        "\n",
        "  <span style=\"color:{STATUS_OK_COLOR};font-size:26px;\">‚óè</span>\n",
        "  <b>Healthy</b> ‚Äì All sensor values within normal ranges<br>\n",
        "\n",
        "  <span style=\"color:{STATUS_WARN_COLOR};font-size:26px;\">‚óè</span>\n",
        "  <b>Warning</b> ‚Äì At least one value near threshold<br>\n",
        "\n",
        "  <span style=\"color:{STATUS_BAD_COLOR};font-size:26px;\">‚óè</span>\n",
        "  <b>Not OK</b> ‚Äì One or more values out of range<br><br>\n",
        "\n",
        "  <span>Status is calculated automatically from sensor data</span>\n",
        "</div>\n",
        "        \"\"\")\n",
        "\n",
        "        gr.Markdown(f\"\"\"\n",
        "<div class=\"legend-card\" style=\"margin-top:14px;padding:14px;border:1px solid var(--border-color-primary)\n",
        ";border-radius:10px;\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  <h4 style=\"margin-bottom:10px; font-size:20px; font-weight:600;\">\n",
        "‚ÑπÔ∏è Valid Value Ranges\n",
        "</h4>\n",
        "\n",
        "\n",
        "  <span style=\"color:{COLOR_TEMP};font-size:26px;\">‚óè</span>\n",
        "  üå°Ô∏è <b>Temperature</b>: 18‚Äì32¬∞C<br>\n",
        "\n",
        "  <span style=\"color:{COLOR_HUM};font-size:26px;\">‚óè</span>\n",
        "  üíß <b>Air Humidity</b>: 35‚Äì75%<br>\n",
        "\n",
        "  <span style=\"color:{COLOR_SOIL};font-size:26px;\">‚óè</span>\n",
        "  üå± <b>Soil Moisture</b>: 20‚Äì60%<br><br>\n",
        "\n",
        "  <span>‚ö†Ô∏è Values outside these ranges are considered abnormal</span>\n",
        "</div>\n",
        "        \"\"\")\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "<h2 style=\"text-align:center; margin-top:22px; font-size:26px; font-weight:600;\">\n",
        "üìà Plant Sensor Graphs\n",
        "</h2>\n",
        "\"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        plot_temp = gr.Plot(label=\"Temperature\")\n",
        "        plot_hum = gr.Plot(label=\"Air Humidity\")\n",
        "\n",
        "    with gr.Row():\n",
        "        plot_soil = gr.Plot(label=\"Soil Moisture\")\n",
        "        plot_combined = gr.Plot(label=\"Combined (Normalized)\")\n",
        "\n",
        "    overall_btn.click(\n",
        "        fn=plant_dashboard,\n",
        "        inputs=[samples],\n",
        "        outputs=[overall_status, overall_info, plot_temp, plot_hum, plot_soil, plot_combined]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diLmmpb6NPNq"
      },
      "source": [
        "‚úÖ TAB 3 LOGIC - üìÑ Generate Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4xGuzaSNQXh"
      },
      "outputs": [],
      "source": [
        "# =========================================================\n",
        "# TAB 1 ‚Äî Generate Report (LOGIC ONLY) | Cerebras LM | ENGLISH\n",
        "# =========================================================\n",
        "\n",
        "\n",
        "def unify_sensor_dfs(dfs: dict) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Convert temperature/humidity/soil dfs into one DataFrame:\n",
        "    timestamp | temperature | humidity | soil\n",
        "    \"\"\"\n",
        "    def prep(df, col):\n",
        "        if df is None or df.empty:\n",
        "            return pd.DataFrame(columns=[\"timestamp\", col])\n",
        "\n",
        "        out = df.copy()\n",
        "        if \"timestamp\" not in out.columns and \"created_at\" in out.columns:\n",
        "            out = out.rename(columns={\"created_at\": \"timestamp\"})\n",
        "\n",
        "        # timestamp may be an index\n",
        "        if \"timestamp\" not in out.columns:\n",
        "            if out.index.name is not None:\n",
        "                out = out.reset_index()\n",
        "            else:\n",
        "                out = out.reset_index().rename(columns={\"index\": \"timestamp\"})\n",
        "\n",
        "        if \"timestamp\" not in out.columns or \"value\" not in out.columns:\n",
        "            return pd.DataFrame(columns=[\"timestamp\", col])\n",
        "\n",
        "        out = out[[\"timestamp\", \"value\"]]\n",
        "        ts = out[\"timestamp\"]\n",
        "\n",
        "        # numeric timestamp (s/ms) OR datetime string\n",
        "        if pd.api.types.is_numeric_dtype(ts) or ts.astype(str).str.fullmatch(r\"\\d+\").all():\n",
        "            ts_num = pd.to_numeric(ts, errors=\"coerce\")\n",
        "            unit = \"ms\" if ts_num.dropna().astype(int).astype(str).str.len().median() >= 13 else \"s\"\n",
        "            out[\"timestamp\"] = (\n",
        "                pd.to_datetime(ts_num, errors=\"coerce\", unit=unit, utc=True)\n",
        "                .dt.tz_convert(\"Asia/Jerusalem\")\n",
        "                .dt.tz_localize(None)\n",
        "            )\n",
        "        else:\n",
        "            out[\"timestamp\"] = (\n",
        "                pd.to_datetime(ts, errors=\"coerce\", utc=True)\n",
        "                .dt.tz_convert(\"Asia/Jerusalem\")\n",
        "                .dt.tz_localize(None)\n",
        "            )\n",
        "\n",
        "        out = out.dropna(subset=[\"timestamp\"])\n",
        "        out[\"value\"] = pd.to_numeric(out[\"value\"], errors=\"coerce\")\n",
        "        out = out.dropna(subset=[\"value\"])\n",
        "\n",
        "        out = out.rename(columns={\"value\": col})\n",
        "        return out\n",
        "\n",
        "    t = prep(dfs.get(\"temperature\"), \"temperature\")\n",
        "    h = prep(dfs.get(\"humidity\"), \"humidity\")\n",
        "    s = prep(dfs.get(\"soil\"), \"soil\")\n",
        "\n",
        "    df = t.merge(h, on=\"timestamp\", how=\"outer\").merge(s, on=\"timestamp\", how=\"outer\")\n",
        "    df = df.sort_values(\"timestamp\").reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "class AutomatedReportGenerator:\n",
        "    \"\"\"\n",
        "    Generate professional reports using AI (Cerebras LM).\n",
        "    Creates daily summaries and Word documents.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cerebras_client, model_name):\n",
        "        self.client = cerebras_client\n",
        "        self.model_name = model_name\n",
        "\n",
        "    def generate_daily_report(self, df: pd.DataFrame) -> str:\n",
        "        \"\"\"Generate AI-powered daily summary (ENGLISH).\"\"\"\n",
        "        if df.empty:\n",
        "            return \"No data available for report.\"\n",
        "\n",
        "        # Get last 24 hours or last 100 readings\n",
        "        try:\n",
        "            cutoff = df[\"timestamp\"].max() - timedelta(hours=24)\n",
        "            daily = df[df[\"timestamp\"] > cutoff]\n",
        "            if daily.empty:\n",
        "                daily = df.tail(100)\n",
        "        except:\n",
        "            daily = df.tail(100)\n",
        "\n",
        "        # Calculate statistics\n",
        "        stats = {\n",
        "            \"date\": daily[\"timestamp\"].max().strftime(\"%Y-%m-%d\"),\n",
        "            \"readings\": len(daily),\n",
        "            \"temp_avg\": daily[\"temperature\"].mean(),\n",
        "            \"temp_min\": daily[\"temperature\"].min(),\n",
        "            \"temp_max\": daily[\"temperature\"].max(),\n",
        "            \"humidity_avg\": daily[\"humidity\"].mean(),\n",
        "            \"humidity_min\": daily[\"humidity\"].min(),\n",
        "            \"humidity_max\": daily[\"humidity\"].max(),\n",
        "            \"soil_avg\": daily[\"soil\"].mean(),\n",
        "            \"soil_min\": daily[\"soil\"].min(),\n",
        "            \"soil_max\": daily[\"soil\"].max(),\n",
        "        }\n",
        "\n",
        "        # Build AI prompt (ENGLISH)\n",
        "        prompt = f\"\"\"Generate a professional daily plant health report based on this data:\n",
        "\n",
        "DATE: {stats['date']}\n",
        "READINGS: {stats['readings']} sensor measurements\n",
        "\n",
        "ENVIRONMENTAL CONDITIONS:\n",
        "- Temperature: {stats['temp_avg']:.1f}¬∞C (range: {stats['temp_min']:.1f}-{stats['temp_max']:.1f}¬∞C)\n",
        "- Humidity: {stats['humidity_avg']:.1f}% (range: {stats['humidity_min']:.1f}-{stats['humidity_max']:.1f}%)\n",
        "- Soil Moisture: {stats['soil_avg']:.1f}% (range: {stats['soil_min']:.1f}-{stats['soil_max']:.1f}%)\n",
        "\n",
        "Generate a concise daily summary (3-4 paragraphs in English) covering:\n",
        "1) Overall environmental conditions\n",
        "2) Risks and potential stress/disease\n",
        "3) Practical care recommendations\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model_name,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an agricultural consultant generating plant health reports in English.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt},\n",
        "                ],\n",
        "                temperature=0.3,\n",
        "                max_tokens=800,\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            return f\"Error generating report: {str(e)}\"\n",
        "\n",
        "    def create_docx_report(self, df: pd.DataFrame, output_path: str) -> str:\n",
        "        \"\"\"Create formatted Word document report.\"\"\"\n",
        "        doc = Document()\n",
        "\n",
        "        # Title\n",
        "        title = doc.add_heading(\"üå± Daily Plant Health Report\", 0)\n",
        "        title.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "\n",
        "        # Date\n",
        "        date_para = doc.add_paragraph()\n",
        "        date_run = date_para.add_run(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\")\n",
        "        date_run.bold = True\n",
        "        date_para.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "\n",
        "        # Executive Summary (AI)\n",
        "        doc.add_heading(\"Executive Summary\", 1)\n",
        "        ai_summary = self.generate_daily_report(df)\n",
        "        doc.add_paragraph(ai_summary)\n",
        "\n",
        "        # Environmental Conditions Table\n",
        "        doc.add_heading(\"Environmental Conditions\", 1)\n",
        "\n",
        "        if not df.empty:\n",
        "            daily = df.tail(100)\n",
        "\n",
        "            table = doc.add_table(rows=4, cols=4)\n",
        "            table.style = \"Light Grid Accent 1\"\n",
        "\n",
        "            headers = table.rows[0].cells\n",
        "            headers[0].text = \"Parameter\"\n",
        "            headers[1].text = \"Current\"\n",
        "            headers[2].text = \"Average\"\n",
        "            headers[3].text = \"Range\"\n",
        "\n",
        "            # Temperature\n",
        "            row1 = table.rows[1].cells\n",
        "            row1[0].text = \"üå°Ô∏è Temperature\"\n",
        "            row1[1].text = f\"{daily['temperature'].iloc[-1]:.1f}¬∞C\"\n",
        "            row1[2].text = f\"{daily['temperature'].mean():.1f}¬∞C\"\n",
        "            row1[3].text = f\"{daily['temperature'].min():.1f}-{daily['temperature'].max():.1f}¬∞C\"\n",
        "\n",
        "            # Humidity\n",
        "            row2 = table.rows[2].cells\n",
        "            row2[0].text = \"üíß Humidity\"\n",
        "            row2[1].text = f\"{daily['humidity'].iloc[-1]:.1f}%\"\n",
        "            row2[2].text = f\"{daily['humidity'].mean():.1f}%\"\n",
        "            row2[3].text = f\"{daily['humidity'].min():.1f}-{daily['humidity'].max():.1f}%\"\n",
        "\n",
        "            # Soil\n",
        "            row3 = table.rows[3].cells\n",
        "            row3[0].text = \"üå± Soil Moisture\"\n",
        "            row3[1].text = f\"{daily['soil'].iloc[-1]:.1f}%\"\n",
        "            row3[2].text = f\"{daily['soil'].mean():.1f}%\"\n",
        "            row3[3].text = f\"{daily['soil'].min():.1f}-{daily['soil'].max():.1f}%\"\n",
        "\n",
        "        # Statistics Summary\n",
        "        doc.add_heading(\"Statistical Summary\", 1)\n",
        "        stats_text = f\"\"\"Total Readings: {len(df)}\n",
        "Time Period: {df['timestamp'].min().strftime('%Y-%m-%d')} to {df['timestamp'].max().strftime('%Y-%m-%d')}\n",
        "Data Points: Temperature, Humidity, Soil Moisture\n",
        "Quality: All sensors operational\"\"\"\n",
        "        doc.add_paragraph(stats_text)\n",
        "\n",
        "        doc.save(output_path)\n",
        "        return output_path\n",
        "\n",
        "\n",
        "# Initialize report generator (same LM flow you already use)\n",
        "report_gen = AutomatedReportGenerator(client, REPORT_MODEL_NAME)\n",
        "\n",
        "\n",
        "def generate_report_screen(limit: int):\n",
        "    \"\"\"\n",
        "    Gradio button handler.\n",
        "    Returns: (status_text, file_path_or_None)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        dfs = {\n",
        "            \"temperature\": load_iot_data(\"temperature\", limit),\n",
        "            \"humidity\": load_iot_data(\"humidity\", limit),\n",
        "            \"soil\": load_iot_data(\"soil\", limit),\n",
        "        }\n",
        "\n",
        "        df = unify_sensor_dfs(dfs)\n",
        "        df = df.dropna(subset=[\"timestamp\"]).sort_values(\"timestamp\").reset_index(drop=True)\n",
        "\n",
        "        if df.empty:\n",
        "            return \"No data available to generate a report.\", None\n",
        "\n",
        "\n",
        "        fd, path = tempfile.mkstemp(suffix=\".docx\", prefix=\"daily_report_\")\n",
        "        os.close(fd)\n",
        "\n",
        "        out_path = report_gen.create_docx_report(df, output_path=path)\n",
        "        return \"‚úÖ Report generated successfully. Download below:\", out_path\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error generating report: {str(e)}\", None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVEFwcIVNtzb"
      },
      "source": [
        "‚úÖ TAB 3 GUI - üìÑ Generate Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ElkHtUANx4I"
      },
      "outputs": [],
      "source": [
        "# =========================================================\n",
        "# TAB 2 ‚Äî Generate Report (GUI ONLY)\n",
        "# =========================================================\n",
        "\n",
        "def build_generate_report_tab():\n",
        "    gr.Markdown(\"## üìÑ Generate Report\")\n",
        "    gr.Markdown(\"Generate a Word (DOCX) report based on sensor data: temperature, humidity, and soil moisture. (English AI summary)\")\n",
        "\n",
        "    report_samples = gr.Slider(\n",
        "        minimum=5,\n",
        "        maximum=200,\n",
        "        value=20,\n",
        "        step=1,\n",
        "        label=\"Number of samples per sensor\"\n",
        "    )\n",
        "\n",
        "    report_btn = gr.Button(\"üì• Generate & Download Report\", variant=\"primary\")\n",
        "    report_status = gr.Textbox(label=\"Status\", lines=2)\n",
        "    report_file = gr.File(label=\"Download DOCX\")\n",
        "\n",
        "    report_btn.click(\n",
        "        fn=generate_report_screen_gamified,   # ◊û◊í◊ô◊¢ ◊û◊î-LOGIC tab\n",
        "        inputs=[report_samples],\n",
        "        outputs=[report_status, report_file]\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U06h9U6aiNy"
      },
      "source": [
        "TAB 4 LOGIC - üñºÔ∏è Plant Disease Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5KpoVVMbX8P"
      },
      "outputs": [],
      "source": [
        "def analyze_plant(image, temp, humidity, soil):\n",
        "    preds = clf(image)\n",
        "    top = preds[0]\n",
        "\n",
        "    label = top[\"label\"]\n",
        "    score = top[\"score\"]\n",
        "\n",
        "    alerts = []\n",
        "    advice = []\n",
        "\n",
        "    # --- Conditions based on sensors / user input ---\n",
        "    if soil < 25:\n",
        "        alerts.append(\"Low soil moisture\")\n",
        "        advice.append(\"Recommendation: irrigate / water the plant\")\n",
        "\n",
        "    if humidity > 80:\n",
        "        alerts.append(\"High humidity\")\n",
        "        advice.append(\"Recommendation: improve ventilation (reduce fungal risk)\")\n",
        "\n",
        "    if temp > 40:\n",
        "        alerts.append(\"High temperature\")\n",
        "        advice.append(\"Recommendation: move the plant to a shaded area\")\n",
        "\n",
        "    # --- Color status (\"flag\") based on image prediction ---\n",
        "    # Simple rule: if label contains \"healthy\" => good (green), else bad (red)\n",
        "    is_bad = (\"healthy\" not in label.lower())\n",
        "\n",
        "    status_html = (\n",
        "        \"<div style='padding:10px;border-radius:10px;\"\n",
        "        f\"background:{'#ffdddd' if is_bad else '#ddffdd'};\"\n",
        "        f\"border:1px solid {'#ff0000' if is_bad else '#00aa00'};\"\n",
        "        \"font-weight:700;'>\"\n",
        "        f\"{'üî¥ Plant status: BAD' if is_bad else 'üü¢ Plant status: GOOD'}\"\n",
        "        \"</div>\"\n",
        "    )\n",
        "\n",
        "    if not alerts:\n",
        "        alerts.append(\"Status looks normal\")\n",
        "\n",
        "    return (\n",
        "        f\"Detected disease: {label} ({score:.2%})\",\n",
        "        status_html,\n",
        "        \"\\n\".join(alerts),\n",
        "        \"\\n\".join(advice)\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZTNbJe1amWj"
      },
      "source": [
        "TAB 4 GUI - üñºÔ∏è Plant Disease Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yt5-ZORrbbt9"
      },
      "outputs": [],
      "source": [
        "def build_plant_disease_detection_tab():\n",
        "    gr.Markdown(\"## üñºÔ∏è Plant Disease Detection\")\n",
        "\n",
        "    with gr.Row():\n",
        "\n",
        "        # -------- LEFT SIDE --------\n",
        "        with gr.Column(scale=2):\n",
        "\n",
        "            image = gr.Image(\n",
        "                type=\"filepath\",\n",
        "                label=\"Upload plant image\",\n",
        "                sources=[\"upload\"]\n",
        "            )\n",
        "\n",
        "            temp = gr.Slider(0, 45, value=25, label=\"Temperature (¬∞C)\")\n",
        "            humidity = gr.Slider(0, 100, value=50, label=\"Humidity (%)\")\n",
        "            soil = gr.Slider(0, 100, value=50, label=\"Soil Moisture (%)\")\n",
        "\n",
        "            run_btn = gr.Button(\"Analyze Plant\", variant=\"primary\")\n",
        "\n",
        "        # -------- RIGHT SIDE --------\n",
        "        with gr.Column(scale=2):\n",
        "\n",
        "            diagnosis = gr.Textbox(\n",
        "                label=\"Diagnosis\",\n",
        "                placeholder=\"Plant disease diagnosis will appear here\"\n",
        "            )\n",
        "\n",
        "            status = gr.HTML(label=\"Status\")\n",
        "\n",
        "            alerts = gr.Textbox(\n",
        "                label=\"Alerts\",\n",
        "                lines=5,\n",
        "                placeholder=\"Sensor alerts and warnings will appear here\"\n",
        "            )\n",
        "\n",
        "            recommendations = gr.Textbox(\n",
        "                label=\"Recommendations\",\n",
        "                lines=5,\n",
        "                placeholder=\"Care and treatment recommendations will appear here\"\n",
        "            )\n",
        "\n",
        "    run_btn.click(\n",
        "        fn=analyze_plant_gamified,\n",
        "        inputs=[image, temp, humidity, soil],\n",
        "        outputs=[diagnosis, status, alerts, recommendations]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkSvfBItbI0T"
      },
      "source": [
        "TAB 5 LOGIC - RAG Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Xg6U8P7bHTm"
      },
      "outputs": [],
      "source": [
        "DOC_URLS = [\n",
        "    \"https://doi.org/10.1038/s41598-025-20629-y\",\n",
        "    \"https://doi.org/10.3389/fpls.2016.01419\",\n",
        "    \"https://doi.org/10.1038/s41598-025-05102-0\",\n",
        "    \"https://doi.org/10.1038/s41598-025-04758-y\",\n",
        "    \"https://doi.org/10.2174/0118743315321139240627092707\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWKeK8JEcfJL"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Cell 3: HTTP / Session setup\n",
        "# =========================\n",
        "# Purpose: Shared HTTP session + helper functions to fetch HTML/PDF and query academic APIs (Semantic Scholar/OpenAlex/Unpaywall).\n",
        "\n",
        "# Reuse a single session for performance and consistent headers/cookies.\n",
        "session = requests.Session()\n",
        "\n",
        "# Browser-like headers to improve compatibility with some sites.\n",
        "BROWSER_HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "}\n",
        "\n",
        "# Normalize DOI input (accept DOI or doi.org URL).\n",
        "def _normalize_doi(doi_or_url: str) -> str:\n",
        "    s = (doi_or_url or \"\").strip()\n",
        "    s = s.replace(\"https://doi.org/\", \"\").replace(\"http://doi.org/\", \"\")\n",
        "    return s.strip()\n",
        "\n",
        "# Fetch HTML and return (html_text, final_url, status_code).\n",
        "def fetch_html(url: str, timeout: int = 25):\n",
        "    r = session.get(url, headers={**BROWSER_HEADERS, \"Accept\": \"text/html,*/*;q=0.8\"}, timeout=timeout, allow_redirects=True)\n",
        "    return (r.text or \"\"), r.url, r.status_code\n",
        "\n",
        "# Extract readable main text from HTML (title/description/body).\n",
        "def extract_main_text_from_html(html: str) -> str:\n",
        "    try:\n",
        "        from bs4 import BeautifulSoup\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Install bs4 + lxml: pip install beautifulsoup4 lxml\")\n",
        "\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "    for tag in soup([\"script\",\"style\",\"noscript\",\"svg\",\"iframe\"]):\n",
        "        tag.decompose()\n",
        "\n",
        "    root = soup.find(\"main\") or soup.find(\"article\") or soup\n",
        "\n",
        "    title = soup.title.string.strip() if soup.title and soup.title.string else \"\"\n",
        "    desc = \"\"\n",
        "    m = soup.find(\"meta\", attrs={\"name\":\"description\"})\n",
        "    if m and m.get(\"content\"):\n",
        "        desc = m[\"content\"].strip()\n",
        "\n",
        "    chunks = []\n",
        "    for el in root.find_all([\"h1\",\"h2\",\"h3\",\"p\",\"li\"]):\n",
        "        t = el.get_text(\" \", strip=True)\n",
        "        if t and len(t) >= 30:\n",
        "            chunks.append(t)\n",
        "\n",
        "    if len(chunks) < 3:\n",
        "        t = re.sub(r\"\\s+\", \" \", root.get_text(\" \", strip=True)).strip()\n",
        "        chunks = [t] if t else []\n",
        "\n",
        "    chunks = list(dict.fromkeys(chunks))\n",
        "    body = \"\\n\".join(chunks).strip()\n",
        "\n",
        "    parts = []\n",
        "    if title: parts.append(f\"TITLE: {title}\")\n",
        "    if desc:  parts.append(f\"DESCRIPTION: {desc}\")\n",
        "    if body:  parts.append(body)\n",
        "    return \"\\n\".join(parts).strip()\n",
        "\n",
        "\n",
        "# API lookup: Semantic Scholar (metadata + possible openAccessPdf).\n",
        "def semantic_scholar_lookup(doi: str):\n",
        "    \"\"\"Return dict with title/abstract and possibly openAccessPdf url.\"\"\"\n",
        "    # No key required for basic use, but rate-limited.\n",
        "    url = f\"https://api.semanticscholar.org/graph/v1/paper/DOI:{quote(doi, safe='')}\"\n",
        "    params = {\"fields\": \"title,abstract,openAccessPdf,url\"}\n",
        "    r = session.get(url, params=params, headers=BROWSER_HEADERS, timeout=25)\n",
        "    if r.status_code != 200:\n",
        "        return None\n",
        "    return r.json()\n",
        "\n",
        "# API lookup: OpenAlex (metadata + locations + inverted-index abstract).\n",
        "def openalex_lookup(doi: str):\n",
        "    url = f\"https://api.openalex.org/works/doi:{quote(doi, safe='')}\"\n",
        "    r = session.get(url, headers=BROWSER_HEADERS, timeout=25)\n",
        "    if r.status_code != 200:\n",
        "        return None\n",
        "    return r.json()\n",
        "\n",
        "# API lookup: Unpaywall (OA locations; requires email parameter).\n",
        "def unpaywall_lookup(doi: str, email: str = \"test@example.com\"):\n",
        "    # Unpaywall requires an email parameter (your real email is best).\n",
        "    url = f\"https://api.unpaywall.org/v2/{quote(doi, safe='')}\"\n",
        "    r = session.get(url, params={\"email\": email}, headers=BROWSER_HEADERS, timeout=25)\n",
        "    if r.status_code != 200:\n",
        "        return None\n",
        "    return r.json()\n",
        "\n",
        "# Select the best PDF URL from available sources (Semantic Scholar/OpenAlex/Unpaywall).\n",
        "def _pick_pdf_url_from_sources(ss=None, oa=None, up=None) -> str:\n",
        "    # 1) Semantic Scholar openAccessPdf\n",
        "    if ss and isinstance(ss, dict):\n",
        "        oap = ss.get(\"openAccessPdf\") or {}\n",
        "        if isinstance(oap, dict) and oap.get(\"url\"):\n",
        "            return oap[\"url\"]\n",
        "\n",
        "    # 2) OpenAlex primary_location / open_access\n",
        "    if oa and isinstance(oa, dict):\n",
        "        pl = oa.get(\"primary_location\") or {}\n",
        "        if isinstance(pl, dict):\n",
        "            pdf = pl.get(\"pdf_url\")\n",
        "            if pdf: return pdf\n",
        "            landing = pl.get(\"landing_page_url\")\n",
        "            if landing and landing.lower().endswith(\".pdf\"):\n",
        "                return landing\n",
        "        oa2 = oa.get(\"open_access\") or {}\n",
        "        if isinstance(oa2, dict):\n",
        "            oa_url = oa2.get(\"oa_url\")\n",
        "            if oa_url and oa_url.lower().endswith(\".pdf\"):\n",
        "                return oa_url\n",
        "\n",
        "    # 3) Unpaywall best_oa_location\n",
        "    if up and isinstance(up, dict):\n",
        "        bol = up.get(\"best_oa_location\") or {}\n",
        "        if isinstance(bol, dict):\n",
        "            pdf = bol.get(\"url_for_pdf\")\n",
        "            if pdf: return pdf\n",
        "            url = bol.get(\"url\")\n",
        "            if url and url.lower().endswith(\".pdf\"):\n",
        "                return url\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "# Download a PDF and extract text from the first pages (bounded by max_pages).\n",
        "def extract_text_from_pdf_url(pdf_url: str, max_pages: int = 8) -> str:\n",
        "    \"\"\"Download PDF and extract text from first max_pages pages.\"\"\"\n",
        "    # Try pypdf first (often installed). Fallback to pdfminer if needed.\n",
        "    r = session.get(pdf_url, headers={**BROWSER_HEADERS, \"Accept\":\"application/pdf,*/*;q=0.8\"}, timeout=40, allow_redirects=True)\n",
        "    if r.status_code != 200 or not r.content:\n",
        "        return \"\"\n",
        "\n",
        "    data = r.content\n",
        "\n",
        "    # pypdf\n",
        "    try:\n",
        "        from pypdf import PdfReader\n",
        "        import io\n",
        "        reader = PdfReader(io.BytesIO(data))\n",
        "        out = []\n",
        "        n = min(len(reader.pages), max_pages)\n",
        "        for i in range(n):\n",
        "            out.append(reader.pages[i].extract_text() or \"\")\n",
        "        text = \"\\n\".join(out).strip()\n",
        "        text = re.sub(r\"\\s+\", \" \", text)\n",
        "        return text.strip()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # pdfminer\n",
        "    try:\n",
        "        from pdfminer.high_level import extract_text\n",
        "        import io\n",
        "        text = extract_text(io.BytesIO(data), maxpages=max_pages) or \"\"\n",
        "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "        return text\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "# Utility: reconstruct OpenAlex inverted-index abstract into ordered text.\n",
        "def _reconstruct_abstract_from_inverted_index(inv: dict) -> str:\n",
        "    \"\"\"\n",
        "    OpenAlex returns abstracts as an inverted index:\n",
        "    {word: [pos1, pos2, ...], ...}\n",
        "    This reconstructs the abstract text in the correct order.\n",
        "    \"\"\"\n",
        "    if not isinstance(inv, dict) or not inv:\n",
        "        return \"\"\n",
        "\n",
        "    # Find max position to size the token list\n",
        "    max_pos = -1\n",
        "    for positions in inv.values():\n",
        "        if isinstance(positions, list) and positions:\n",
        "            mp = max(positions)\n",
        "            if mp > max_pos:\n",
        "                max_pos = mp\n",
        "\n",
        "    if max_pos < 0:\n",
        "        return \"\"\n",
        "\n",
        "    tokens = [\"\"] * (max_pos + 1)\n",
        "\n",
        "    for word, positions in inv.items():\n",
        "        if not isinstance(positions, list):\n",
        "            continue\n",
        "        for p in positions:\n",
        "            if isinstance(p, int) and 0 <= p < len(tokens):\n",
        "                tokens[p] = word\n",
        "\n",
        "    # Join; remove empties\n",
        "    text = \" \".join(t for t in tokens if t)\n",
        "    return text.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtNn87uDcpAW"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 4. DOI Metadata fallback (only if HTML is short)\n",
        "# =========================\n",
        "# Purpose: Fetch usable document text from a URL with fallbacks:\n",
        "# HTML -> Open-Access PDF (via APIs) -> Abstract metadata -> Title-only.\n",
        "\n",
        "\n",
        "def get_document_text(url: str, min_chars: int = 800, unpaywall_email: str = \"test@example.com\", debug: bool = False) -> str:\n",
        "    \"\"\"\n",
        "    Returns the best available text we can legally obtain.\n",
        "    Order:\n",
        "      1) HTML extraction (if enough)\n",
        "      2) OA PDF extraction via Semantic Scholar / OpenAlex / Unpaywall (if available)\n",
        "      3) Abstract via Semantic Scholar/OpenAlex (fallback)\n",
        "      4) Title only\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Try extracting text directly from the landing HTML page.\n",
        "    html, final_url, status = fetch_html(url)\n",
        "    text_html = extract_main_text_from_html(html) if html else \"\"\n",
        "\n",
        "    # Optional debug printing for tracing which path is used.\n",
        "    if debug:\n",
        "        print(\"final_url:\", final_url)\n",
        "        print(\"html_status:\", status, \"| html_text_chars:\", len(text_html))\n",
        "\n",
        "    # If HTML content is sufficient, return it immediately.\n",
        "    if len(text_html) >= min_chars:\n",
        "        return text_html\n",
        "\n",
        "    # 2) If input is a DOI link, try Open-Access routes (PDF).\n",
        "    doi = _normalize_doi(url) if \"doi.org/\" in (url or \"\") else \"\"\n",
        "    ss = oa = up = None\n",
        "\n",
        "    if doi:\n",
        "        # Query multiple services to maximize chances of finding an OA PDF.\n",
        "        try:\n",
        "            ss = semantic_scholar_lookup(doi)\n",
        "        except Exception:\n",
        "            ss = None\n",
        "        try:\n",
        "            oa = openalex_lookup(doi)\n",
        "        except Exception:\n",
        "            oa = None\n",
        "        try:\n",
        "            up = unpaywall_lookup(doi, email=unpaywall_email)\n",
        "        except Exception:\n",
        "            up = None\n",
        "\n",
        "        # Pick the best PDF URL from the available sources (if any).\n",
        "        pdf_url = _pick_pdf_url_from_sources(ss=ss, oa=oa, up=up)\n",
        "        if debug:\n",
        "            print(\"pdf_url:\", pdf_url or \"(none)\")\n",
        "\n",
        "        # If we found a PDF, extract text from the first pages.\n",
        "        if pdf_url:\n",
        "            pdf_text = extract_text_from_pdf_url(pdf_url, max_pages=8)\n",
        "            if debug:\n",
        "                print(\"pdf_text_chars:\", len(pdf_text))\n",
        "            if len(pdf_text) >= min_chars:\n",
        "                # Optionally prepend a title header when available.\n",
        "                title = (ss or {}).get(\"title\") or (oa or {}).get(\"title\") or \"\"\n",
        "                title = title.get(\"display_name\") if isinstance(title, dict) else title\n",
        "                header = f\"TITLE: {title}\".strip() if title else \"\"\n",
        "                return (header + \"\\n\" + pdf_text).strip()\n",
        "\n",
        "        # 3) If PDF is missing/short, fall back to abstract metadata (when present).\n",
        "        title = \"\"\n",
        "        abstract = \"\"\n",
        "\n",
        "        if ss and isinstance(ss, dict):\n",
        "            title = (ss.get(\"title\") or \"\").strip()\n",
        "            abstract = (ss.get(\"abstract\") or \"\").strip()\n",
        "\n",
        "        if (not abstract) and oa and isinstance(oa, dict):\n",
        "            t = oa.get(\"title\") or \"\"\n",
        "            title = title or t\n",
        "            # OpenAlex abstract can be stored as an inverted index.\n",
        "            inv = oa.get(\"abstract_inverted_index\")\n",
        "            if inv:\n",
        "                abstract = _reconstruct_abstract_from_inverted_index(inv)\n",
        "\n",
        "        # Return any metadata we managed to obtain.\n",
        "        if title or abstract:\n",
        "            parts = []\n",
        "            if title: parts.append(f\"TITLE: {title}\")\n",
        "            if abstract: parts.append(f\"ABSTRACT: {abstract}\")\n",
        "            return \"\\n\".join(parts).strip()\n",
        "\n",
        "    # 4) Last resort: return thin HTML (title/description) if present.\n",
        "    if text_html:\n",
        "        return text_html.strip()\n",
        "\n",
        "    # Final fallback: return the URL as a minimal title marker.\n",
        "    return f\"TITLE: {url}\".strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sN9YEitTctBm"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 5. NLP Preprocessing\n",
        "# =========================\n",
        "# Purpose: Standardize text into comparable tokens for indexing/search.\n",
        "# Pipeline: tokenize -> stopword removal -> stemming.\n",
        "\n",
        "def tokenize(text):\n",
        "    \"\"\"Convert text to a list of lowercase word tokens.\"\"\"\n",
        "    return re.findall(r\"\\w+\", (text or \"\").lower())\n",
        "\n",
        "def remove_stopwords(tokens, stop_words):\n",
        "    \"\"\"Remove stop words from a list of tokens.\"\"\"\n",
        "    return [t for t in tokens if t not in stop_words]\n",
        "\n",
        "def apply_stemming(tokens):\n",
        "    \"\"\"Apply Porter stemming to a list of tokens.\"\"\"\n",
        "    return [stemmer.stem(t) for t in tokens]\n",
        "\n",
        "\n",
        "def preprocess_query(query: str):\n",
        "    # Goal: Apply the same normalization steps used for documents to the user query.\n",
        "    tokens = tokenize(query)\n",
        "    tokens = remove_stopwords(tokens, stop_words)\n",
        "    tokens = apply_stemming(tokens)\n",
        "    return tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnI_A-yScy4j"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 6. Document Text Access\n",
        "# =========================\n",
        "# Purpose: Fetch and store raw text for each document URL so it can be indexed later.\n",
        "# Output: doc_text dict mapping doc_id -> extracted text (may be empty on failure).\n",
        "\n",
        "def build_doc_text_map(doc_urls, min_chars=800, unpaywall_email=\"test@example.com\", debug=False):\n",
        "    doc_text = {}\n",
        "    for i, url in enumerate(doc_urls):\n",
        "        # Try to extract the best available text (HTML/PDF/abstract fallback).\n",
        "        try:\n",
        "            doc_text[i] = get_document_text(\n",
        "                url,\n",
        "                min_chars=min_chars,\n",
        "                unpaywall_email=unpaywall_email,\n",
        "                debug=debug\n",
        "            ) or \"\"\n",
        "        except Exception as e:\n",
        "            # Keep the pipeline running even if a document fails to fetch.\n",
        "            print(f\"Failed to fetch document {i}: {e}\")\n",
        "            doc_text[i] = \"\"\n",
        "    return doc_text\n",
        "\n",
        "\n",
        "# Placeholder / initialization for the document-text mapping (doc_id -> text).\n",
        "doc_text = {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQYDi7e4c0oG"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 7. Index Construction\n",
        "# =========================\n",
        "# Purpose: Build an inverted index for fast keyword-based retrieval.\n",
        "# - Input: raw document texts (doc_text) and preprocessing settings (stop_words).\n",
        "# - Output:\n",
        "#   1) inverted: term -> list of doc_ids containing the term\n",
        "#   2) doc_map: doc_id -> original URL\n",
        "\n",
        "def build_inverted_index(urls, stop_words, doc_text):\n",
        "    inverted = defaultdict(set)  # term -> set(doc_ids)\n",
        "    doc_map = {i: url for i, url in enumerate(urls)}  # DocID -> URL\n",
        "\n",
        "    for doc_id in range(len(urls)):\n",
        "        # Get the stored text for this document (support int or string keys).\n",
        "        text = doc_text.get(doc_id) or doc_text.get(str(doc_id)) or \"\"\n",
        "\n",
        "        # Normalize document text into searchable terms.\n",
        "        tokens = tokenize(text)\n",
        "        tokens = remove_stopwords(tokens, stop_words)\n",
        "        tokens = apply_stemming(tokens)\n",
        "\n",
        "        # Add each unique term to the index for this document.\n",
        "        for term in set(tokens):\n",
        "            inverted[term].add(doc_id)\n",
        "\n",
        "    # Convert sets to sorted lists for stable output/serialization.\n",
        "    inverted = {term: sorted(list(ids)) for term, ids in inverted.items()}\n",
        "    return inverted, doc_map\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpwLmT6Fc9BT"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 8. Firebase I/O\n",
        "# =========================\n",
        "# Purpose: Persist and reuse the document store in Firebase.\n",
        "# Stored objects:\n",
        "# - doc_text: doc_id -> extracted text\n",
        "# - public_index: inverted index (term -> doc_ids)\n",
        "# - doc_map: doc_id -> source URL\n",
        "\n",
        "def save_to_firebase(data, path):\n",
        "    # Write JSON data to a Firebase Realtime Database path using HTTP PUT.\n",
        "    base = FIREBASE_URL.rstrip(\"/\")\n",
        "    url = f\"{base}/{path}.json\"\n",
        "    r = requests.put(url, json=data, timeout=30)\n",
        "    print(\"PUT\", path, \"status:\", r.status_code, \"| resp:\", r.text[:200])\n",
        "    if r.status_code != 200:\n",
        "        raise RuntimeError(f\"PUT {path} failed: {r.status_code} | {r.text[:400]}\")\n",
        "    return r.status_code, r.text\n",
        "\n",
        "\n",
        "def firebase_get(path):\n",
        "    # Read JSON data from a Firebase Realtime Database path using HTTP GET.\n",
        "    base = FIREBASE_URL.rstrip(\"/\")\n",
        "    url = f\"{base}/{path}.json\"\n",
        "    r = requests.get(url, timeout=30)\n",
        "    print(\"GET\", path, \"status:\", r.status_code, \"| resp:\", r.text[:200])\n",
        "    if r.status_code != 200:\n",
        "        raise RuntimeError(f\"GET {path} failed: {r.status_code} | {r.text[:400]}\")\n",
        "    return r.json()\n",
        "\n",
        "\n",
        "def build_and_save_index(\n",
        "    urls,\n",
        "    stop_words,\n",
        "    index_path=\"indexes/public_index\",\n",
        "    map_path=\"indexes/doc_map\",\n",
        "    text_path=\"indexes/doc_text\"):\n",
        "    # Orchestrator: build doc_text + inverted index locally, then save all artifacts to Firebase.\n",
        "\n",
        "    # 1) Build doc_text locally\n",
        "    doc_text_local = build_doc_text_map(urls)\n",
        "\n",
        "    # Save doc_text with string keys (JSON consistency)\n",
        "    doc_text_to_save = {str(k): v for k, v in doc_text_local.items()}\n",
        "    save_to_firebase(doc_text_to_save, text_path)\n",
        "    print(\"‚úÖ doc_text saved\")\n",
        "\n",
        "    # 2) Build index + doc_map using doc_text_local\n",
        "    inv_index, doc_map = build_inverted_index(urls, stop_words, doc_text_local)\n",
        "\n",
        "    # Save doc_map with string keys\n",
        "    doc_map_json = {str(k): v for k, v in doc_map.items()}\n",
        "    save_to_firebase(inv_index, index_path)\n",
        "    print(\"‚úÖ index saved\")\n",
        "\n",
        "    save_to_firebase(doc_map_json, map_path)\n",
        "    print(\"‚úÖ doc_map saved\")\n",
        "\n",
        "    return inv_index, doc_map_json, doc_text_local\n",
        "\n",
        "# Load existing store from Firebase if present; otherwise build once and save.\n",
        "existing_index = firebase_get(\"indexes/public_index\")  # None if missing\n",
        "existing_map   = firebase_get(\"indexes/doc_map\")\n",
        "existing_text  = firebase_get(\"indexes/doc_text\")\n",
        "\n",
        "if existing_index is not None and existing_map is not None and existing_text is not None:\n",
        "    # Reuse cached data to avoid rebuilding/re-fetching documents.\n",
        "    inv_index = existing_index\n",
        "    doc_map_json = existing_map\n",
        "    doc_text_local = existing_text\n",
        "    print(\"‚úÖ Loaded existing store from Firebase (no rebuild).\")\n",
        "else:\n",
        "    # First-time setup: build and persist the store.\n",
        "    inv_index, doc_map_json, doc_text_local = build_and_save_index(DOC_URLS, stop_words)\n",
        "    print(\"‚úÖ Built and saved store to Firebase.\")\n",
        "\n",
        "# Expose globals used by retrieval/search code.\n",
        "public_index = inv_index\n",
        "doc_map = doc_map_json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ymnru7rrdERK"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 9 Load store from Firebase\n",
        "# =========================\n",
        "# Purpose: Load previously saved index artifacts from Firebase into runtime globals.\n",
        "# Loads: public_index (inverted index), doc_map (doc_id -> URL), and optionally doc_text.\n",
        "\n",
        "INDEX_PATH = \"indexes/public_index\"\n",
        "MAP_PATH   = \"indexes/doc_map\"\n",
        "TEXT_PATH  = \"indexes/doc_text\"\n",
        "\n",
        "public_index = None\n",
        "doc_map = None\n",
        "doc_text = None\n",
        "\n",
        "def load_store_from_firebase(load_text: bool = False):\n",
        "    # Load index + doc_map from Firebase into globals\n",
        "    global public_index, doc_map, doc_text\n",
        "\n",
        "    # Always load index and doc_map (use empty dict if missing).\n",
        "    public_index = firebase_get(INDEX_PATH) or {}\n",
        "    doc_map = firebase_get(MAP_PATH) or {}\n",
        "\n",
        "    # Normalize doc_map shape if Firebase returns a JSON array instead of an object.\n",
        "    if isinstance(doc_map, list):\n",
        "      doc_map = {str(i): v for i, v in enumerate(doc_map)}\n",
        "\n",
        "    # Optionally load the full document texts (can be large).\n",
        "    if load_text:\n",
        "        doc_text = firebase_get(TEXT_PATH) or {}\n",
        "\n",
        "    # Basic summary for quick sanity-check.\n",
        "    print(\"Loaded:\",\n",
        "          \"terms=\", len(public_index),\n",
        "          \"| docs=\", len(doc_map) if hasattr(doc_map, \"__len__\") else type(doc_map))\n",
        "\n",
        "    return public_index, doc_map, doc_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRF_hY27dKdi"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 10. Retrieval (uses data loaded from Firebase)\n",
        "# =========================\n",
        "# Purpose: Perform simple keyword-based retrieval using the inverted index.\n",
        "# Method: preprocess query -> count matching terms per document -> return top-k docs.\n",
        "\n",
        "def search_top_k(query: str, k: int = 3):\n",
        "    # Ensure index and doc_map are available in memory (load if missing).\n",
        "    if public_index is None or doc_map is None:\n",
        "        load_store_from_firebase(load_text=False)\n",
        "\n",
        "    # Convert the raw query into normalized terms (tokenize/stopwords/stemming).\n",
        "    q_terms = preprocess_query(query)\n",
        "    scores = defaultdict(int)\n",
        "\n",
        "    # Score documents by how many query terms they contain.\n",
        "    for term in q_terms:\n",
        "        for doc_id in (public_index.get(term, []) or []):\n",
        "            scores[int(doc_id)] += 1\n",
        "\n",
        "    # Rank by score and keep the top-k.\n",
        "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:k]\n",
        "\n",
        "    # Build a compact result list with doc id, score, and source URL.\n",
        "    results = []\n",
        "    for doc_id, score in ranked:\n",
        "        url = doc_map.get(str(doc_id)) if isinstance(doc_map, dict) else None\n",
        "        results.append({\"doc_id\": doc_id, \"score\": score, \"url\": url})\n",
        "\n",
        "    return q_terms, results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2o5n47cdLRO"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 11. RAG ‚Äì Generation (FAST SMALL MODEL) [FULL FIXED CELL]\n",
        "# =========================\n",
        "# Keeps the same public function names:\n",
        "# - get_doc_text(doc_id)\n",
        "# - rag_generate_answer(query, k, snippet_chars)\n",
        "# - rag_generate_answer_from_results(query, q_terms, results, snippet_chars)\n",
        "\n",
        "import re\n",
        "\n",
        "# Per-document cache to avoid repeated Firebase GETs\n",
        "_doc_text_cache = {}\n",
        "\n",
        "def get_doc_text(doc_id: int) -> str:\n",
        "    \"\"\"\n",
        "    Fetch a single document's text from Firebase (Realtime DB) at:\n",
        "    indexes/doc_text/<doc_id>\n",
        "    Uses a small in-memory cache for speed.\n",
        "    \"\"\"\n",
        "    key = str(int(doc_id))\n",
        "\n",
        "    if key in _doc_text_cache:\n",
        "        return _doc_text_cache[key] or \"\"\n",
        "\n",
        "    text_base = globals().get(\"TEXT_PATH\", \"indexes/doc_text\")\n",
        "\n",
        "    try:\n",
        "        txt = firebase_get(f\"{text_base}/{key}\")\n",
        "    except Exception:\n",
        "        txt = \"\"\n",
        "\n",
        "    if txt is None:\n",
        "        txt = \"\"\n",
        "\n",
        "    if not isinstance(txt, str):\n",
        "        txt = str(txt)\n",
        "\n",
        "    _doc_text_cache[key] = txt\n",
        "    return txt\n",
        "\n",
        "\n",
        "# Try to load a SMALL HuggingFace generation model (faster than large/base).\n",
        "try:\n",
        "    import torch\n",
        "    from transformers import pipeline\n",
        "    _GEN_AVAILABLE = True\n",
        "except Exception as e:\n",
        "    _GEN_AVAILABLE = False\n",
        "    _GEN_ERR = e\n",
        "\n",
        "gen = None\n",
        "if _GEN_AVAILABLE:\n",
        "    device = 0 if torch.cuda.is_available() else -1\n",
        "    try:\n",
        "        gen = pipeline(\n",
        "            \"text2text-generation\",\n",
        "            model=\"google/flan-t5-small\",\n",
        "            device=device\n",
        "        )\n",
        "    except Exception:\n",
        "        # Fallback to base (slower than small, still usually faster than large)\n",
        "        try:\n",
        "            gen = pipeline(\n",
        "                \"text2text-generation\",\n",
        "                model=\"google/flan-t5-base\",\n",
        "                device=device\n",
        "            )\n",
        "        except Exception as e:\n",
        "            gen = None\n",
        "            _GEN_ERR = e\n",
        "\n",
        "\n",
        "def _safe_snip(text: str, n: int) -> str:\n",
        "    \"\"\"\n",
        "    Cut text to ~n chars but avoid cutting in the middle of a word.\n",
        "    \"\"\"\n",
        "    text = text or \"\"\n",
        "    if len(text) <= n:\n",
        "        return text\n",
        "\n",
        "    snip = text[:n]\n",
        "\n",
        "    # Move back to the last whitespace to avoid mid-word cuts\n",
        "    if \" \" in snip:\n",
        "        snip = snip.rsplit(\" \", 1)[0]\n",
        "\n",
        "    return snip.strip()\n",
        "\n",
        "\n",
        "def _extract_description(doc_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Return only the DESCRIPTION part (if exists).\n",
        "    This avoids the model copying the TITLE as the \"answer\".\n",
        "    \"\"\"\n",
        "    t = doc_text or \"\"\n",
        "    key = \"DESCRIPTION:\"\n",
        "    i = t.find(key)\n",
        "    if i == -1:\n",
        "        return t.strip()\n",
        "    return t[i + len(key):].strip()\n",
        "\n",
        "\n",
        "def _build_context(results, snippet_chars: int = 160) -> str:\n",
        "    \"\"\"\n",
        "    Build a single context string by concatenating top retrieved document snippets.\n",
        "    IMPORTANT: Use only DESCRIPTION (no TITLE/URL) to reduce noise and token waste.\n",
        "    \"\"\"\n",
        "    parts = []\n",
        "    for r in results:\n",
        "        doc_id = r[\"doc_id\"]\n",
        "        raw = get_doc_text(doc_id) or \"\"\n",
        "        desc = _extract_description(raw)\n",
        "        text = _safe_snip(desc, snippet_chars)\n",
        "        parts.append(f\"[Doc {doc_id}]\\n{text}\")\n",
        "    return \"\\n\\n---\\n\\n\".join(parts)\n",
        "\n",
        "\n",
        "def _fallback_answer(query: str, results, snippet_chars: int = 160) -> str:\n",
        "    \"\"\"\n",
        "    If no generation model is available, return retrieved snippets as a proof of retrieval.\n",
        "    Uses DESCRIPTION-first behavior.\n",
        "    \"\"\"\n",
        "    lines = [\"(No generation model loaded. Showing retrieved snippets.)\\n\"]\n",
        "    lines.append(f\"Question: {query}\\n\")\n",
        "    for r in results:\n",
        "        doc_id = r[\"doc_id\"]\n",
        "        url = r.get(\"url\")\n",
        "        raw = get_doc_text(doc_id) or \"\"\n",
        "        desc = _extract_description(raw)\n",
        "        text = _safe_snip(desc, snippet_chars)\n",
        "        lines.append(f\"[Doc {doc_id}] {url}\\n{text}\\n\")\n",
        "    return \"\\n---\\n\".join(lines)\n",
        "\n",
        "\n",
        "def _bad_answer(ans: str) -> bool:\n",
        "    \"\"\"\n",
        "    Detect broken / useless answers (e.g., too short or mostly citations).\n",
        "    \"\"\"\n",
        "    s = (ans or \"\").strip()\n",
        "    if len(s) < 30:\n",
        "        return True\n",
        "\n",
        "    no_cites = re.sub(r\"\\[Doc\\s*\\d+\\]\", \"\", s).strip()\n",
        "    if len(no_cites) < 30:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "def _call_gen(prompt: str, max_new_tokens: int = 160) -> str:\n",
        "    \"\"\"\n",
        "    Call generation pipeline with safe defaults.\n",
        "    Try truncation/max_length if supported; otherwise fallback to basic call.\n",
        "    \"\"\"\n",
        "    if gen is None:\n",
        "        return \"\"\n",
        "\n",
        "    model_max_len = 512\n",
        "    try:\n",
        "        model_max_len = int(getattr(gen.tokenizer, \"model_max_length\", 512))\n",
        "    except Exception:\n",
        "        model_max_len = 512\n",
        "\n",
        "    try:\n",
        "        out = gen(\n",
        "            prompt,\n",
        "            do_sample=False,\n",
        "            num_beams=1,\n",
        "            max_new_tokens=int(max_new_tokens),\n",
        "            truncation=True,\n",
        "            max_length=model_max_len\n",
        "        )[0][\"generated_text\"]\n",
        "        return out\n",
        "    except TypeError:\n",
        "        out = gen(\n",
        "            prompt,\n",
        "            do_sample=False,\n",
        "            num_beams=1,\n",
        "            max_new_tokens=int(max_new_tokens)\n",
        "        )[0][\"generated_text\"]\n",
        "        return out\n",
        "\n",
        "\n",
        "def rag_generate_answer(query: str, k: int = 3, snippet_chars: int = 160):\n",
        "    # Pipeline: retrieve top-k -> build context (top-3 only) -> generate answer (or fallback).\n",
        "    q_terms, results = search_top_k(query, k)\n",
        "\n",
        "    if not results:\n",
        "        return q_terms, results, \"No documents matched the query terms.\"\n",
        "\n",
        "    # Clamp snippet_chars for stability\n",
        "    snippet_chars = min(max(int(snippet_chars), 60), 220)\n",
        "\n",
        "    # Use only top-3 docs for model context (even if k is larger)\n",
        "    context_results = results[:3]\n",
        "    context = _build_context(context_results, snippet_chars=snippet_chars)\n",
        "\n",
        "    if gen is None:\n",
        "        return q_terms, results, _fallback_answer(query, results, snippet_chars=snippet_chars)\n",
        "\n",
        "    prompt = (\n",
        "        \"Answer the question ONLY using the provided context.\\n\"\n",
        "        \"If the context does not contain enough information, say: I don't have enough information.\\n\"\n",
        "        \"Be concise (1-3 sentences).\\n\\n\"\n",
        "        f\"Question: {query}\\n\\n\"\n",
        "        f\"Context:\\n{context}\\n\\n\"\n",
        "        \"Answer (include citations like [Doc 0], [Doc 2]):\"\n",
        "    )\n",
        "\n",
        "    out = _call_gen(prompt, max_new_tokens=160)\n",
        "\n",
        "    if _bad_answer(out):\n",
        "        out = \"I don't have enough information.\"\n",
        "\n",
        "    return q_terms, results, out\n",
        "\n",
        "\n",
        "def rag_generate_answer_from_results(query: str, q_terms, results, snippet_chars: int = 160):\n",
        "    # Same generation logic, but assumes retrieval was already done externally.\n",
        "    if not results:\n",
        "        return q_terms, results, \"No documents matched the query terms.\"\n",
        "\n",
        "    snippet_chars = min(max(int(snippet_chars), 60), 220)\n",
        "\n",
        "    # Keep consistent behavior: only top-3 docs for context\n",
        "    context_results = results[:3]\n",
        "    context = _build_context(context_results, snippet_chars=snippet_chars)\n",
        "\n",
        "    if gen is None:\n",
        "        return q_terms, results, _fallback_answer(query, results, snippet_chars=snippet_chars)\n",
        "\n",
        "    prompt = (\n",
        "        \"Answer the question ONLY using the provided context.\\n\"\n",
        "        \"If the context does not contain enough information, say: I don't have enough information.\\n\"\n",
        "        \"Be concise (1-3 sentences).\\n\\n\"\n",
        "        f\"Question: {query}\\n\\n\"\n",
        "        f\"Context:\\n{context}\\n\\n\"\n",
        "        \"Answer (include citations like [Doc 0], [Doc 2]):\"\n",
        "    )\n",
        "\n",
        "    out = _call_gen(prompt, max_new_tokens=160)\n",
        "\n",
        "    if _bad_answer(out):\n",
        "        out = \"I don't have enough information.\"\n",
        "\n",
        "    return q_terms, results, out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDmVbDIzdSFr"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 12. Presentation Layer\n",
        "# =========================\n",
        "# Purpose: Display retrieval results (top-k documents + snippets) and then print a RAG-generated answer.\n",
        "\n",
        "def show_retrieval_context(query: str, k: int = 3, snippet_chars: int = 700, gen_context_chars: int = 1200):\n",
        "    # Run retrieval to get processed query terms and ranked documents.\n",
        "    q_terms, results = search_top_k(query, k)\n",
        "\n",
        "    # Print a short summary of the query and preprocessing output.\n",
        "    print(\"Query:\", query)\n",
        "    print(\"Processed query terms:\", q_terms)\n",
        "    print(\"\\nTop retrieved documents:\\n\")\n",
        "\n",
        "    # Exit early if no documents matched any query terms.\n",
        "    if not results:\n",
        "        print(\"No documents matched the query terms.\")\n",
        "        return\n",
        "\n",
        "    # Print each retrieved document with its score and a short text preview.\n",
        "    for i, r in enumerate(results, 1):\n",
        "        doc_id = r[\"doc_id\"]\n",
        "        score  = r[\"score\"]\n",
        "        url    = r.get(\"url\")\n",
        "        text   = get_doc_text(doc_id)\n",
        "\n",
        "        print(f\"--- Document {i} ---\")\n",
        "        print(\"Doc ID:\", doc_id)\n",
        "        print(\"Score :\", score)\n",
        "        print(\"URL   :\", url)\n",
        "        print(\"Text snippet:\")\n",
        "        print((text or \"\")[:snippet_chars])\n",
        "        print()\n",
        "\n",
        "    # Generate and print a final answer using the retrieved results as context.\n",
        "    _, _, answer = rag_generate_answer_from_results(query, q_terms, results, snippet_chars=gen_context_chars)\n",
        "    print(\"=== RAG Answer ===\")\n",
        "    print(answer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXsIyqVwdT-C"
      },
      "source": [
        "TAB 5 GUI - RAG Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjpGYYp8dUSJ"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 13. Query Screen GUI (Gradio) + Token Debug\n",
        "# =========================\n",
        "# Purpose: Provide a tab UI to run queries against the index and show retrieval + RAG answer.\n",
        "# Adds a debug panel that shows an approximate token count vs the model's max length.\n",
        "# This helps detect truncation when increasing Top-K.\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def build_rag_chat_tab():\n",
        "\n",
        "    gr.Markdown(\"## üí¨ RAG Chat\")\n",
        "    gr.Markdown(\"Type a query ‚Üí retrieve top-k documents ‚Üí generate an AI answer.\")\n",
        "\n",
        "    question = gr.Textbox(\n",
        "        label=\"üîç Query\",\n",
        "        placeholder=\"e.g., What are symptoms of bacterial wilt in tomato?\",\n",
        "        lines=2\n",
        "    )\n",
        "    n_results = gr.Slider(minimum=1, maximum=5, value=3, step=1, label=\"Top-K documents\")\n",
        "\n",
        "    run_btn = gr.Button(\"Run\", variant=\"primary\")\n",
        "\n",
        "    retrieved_df = gr.Dataframe(\n",
        "        headers=[\"doc_id\", \"score\", \"url\"],\n",
        "        label=\"üìÑ Retrieved documents (ranked)\",\n",
        "        wrap=True\n",
        "    )\n",
        "    answer_box = gr.Textbox(label=\"ü§ñ RAG Answer\", lines=12)\n",
        "\n",
        "    # Debug output (shows token counts / truncation risk)\n",
        "    debug_md = gr.Markdown()\n",
        "\n",
        "    def ui_query_in_tab(q: str, k: int):\n",
        "        if not q or not q.strip():\n",
        "            return [], \"Please enter a question.\", \"\"\n",
        "\n",
        "        q_terms, results, answer = rag_generate_answer(q, k=int(k))\n",
        "\n",
        "        rows = []\n",
        "        for r in results:\n",
        "            rows.append([r.get(\"doc_id\"), r.get(\"score\"), r.get(\"url\")])\n",
        "\n",
        "        # ---- TOKEN DEBUG (best-effort) ----\n",
        "        debug_text = \"\"\n",
        "        try:\n",
        "            # Only if a generation pipeline exists and exposes a tokenizer\n",
        "            if \"gen\" in globals() and gen is not None and hasattr(gen, \"tokenizer\"):\n",
        "                # Build an approximate prompt similar to rag_generate_answer\n",
        "                if \"_build_context\" in globals():\n",
        "                    # Use the same snippet length you use in Cell 11 (adjust if different)\n",
        "                    ctx = _build_context(results, snippet_chars=160)\n",
        "                    prompt = (\n",
        "                        \"Answer the question ONLY using the provided context. \"\n",
        "                        \"If the context does not contain enough information, say: I don't have enough information.\\n\\n\"\n",
        "                        f\"Question: {q}\\n\\n\"\n",
        "                        f\"Context:\\n{ctx}\\n\\n\"\n",
        "                        \"Answer (include citations like [Doc 0], [Doc 2]):\"\n",
        "                    )\n",
        "                    prompt_tokens = len(gen.tokenizer(prompt).input_ids)\n",
        "                    max_len = getattr(gen.tokenizer, \"model_max_length\", None)\n",
        "\n",
        "                    warn = \"\"\n",
        "                    if max_len is not None and prompt_tokens > max_len:\n",
        "                        warn = \" ‚ö†Ô∏è likely truncation (prompt > max)\"\n",
        "\n",
        "                    debug_text = f\"**Token debug:** tokens={prompt_tokens} / max={max_len} | k={int(k)}{warn}\"\n",
        "                else:\n",
        "                    debug_text = \"**Token debug:** _build_context not found (cannot estimate prompt length).\"\n",
        "            else:\n",
        "                debug_text = \"**Token debug:** generator not loaded (gen is None) or tokenizer unavailable.\"\n",
        "        except Exception as e:\n",
        "            debug_text = f\"**Token debug error:** {e}\"\n",
        "\n",
        "        return rows, answer, debug_text\n",
        "\n",
        "    run_btn.click(\n",
        "        fn=ui_query_in_tab,\n",
        "        inputs=[question, n_results],\n",
        "        outputs=[retrieved_df, answer_box, debug_md]\n",
        "    )\n",
        "\n",
        "    question.submit(\n",
        "        fn=ui_query_in_tab,\n",
        "        inputs=[question, n_results],\n",
        "        outputs=[retrieved_df, answer_box, debug_md]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TAB 7 LOGIC - üéÆ Farm Rewards (Gamification)"
      ],
      "metadata": {
        "id": "nSheZbYYkpE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# LOGIC ‚Äî Mission Rewards System (Gamification)\n",
        "# =========================================================\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1) Configuration + Firebase Storage Path\n",
        "#    - Where we store the profile (global, no username)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "TZ_NAME = \"Asia/Jerusalem\"\n",
        "GAMIFICATION_REF = db.reference(\"gamification/global\")\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2) Time Helpers\n",
        "#    - Used for \"once per day\" missions and timestamps\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def _today_key():\n",
        "    from datetime import datetime\n",
        "    from zoneinfo import ZoneInfo\n",
        "    return datetime.now(ZoneInfo(TZ_NAME)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "def _now_iso():\n",
        "    from datetime import datetime\n",
        "    from zoneinfo import ZoneInfo\n",
        "    return datetime.now(ZoneInfo(TZ_NAME)).isoformat()\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3) Default Profile Model\n",
        "#    - The schema we expect to exist in Firebase\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "DEFAULT_PROFILE = {\n",
        "    \"points\": 0,\n",
        "    \"spins_available\": 0,  # 1 spin token per completed mission\n",
        "    \"missions\": {\n",
        "        \"sync_data\": {\"last_completed\": None, \"total_completed\": 0},\n",
        "        \"analyze_plant\": {\"last_completed\": None, \"total_completed\": 0},\n",
        "        \"generate_report\": {\"last_completed\": None, \"total_completed\": 0},\n",
        "    },\n",
        "    \"coupons\": []  # list of dicts: {code,label,created_at,redeemed}\n",
        "}\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4) Profile I/O (Read / Write)\n",
        "#    - Loads from Firebase and merges missing keys safely\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def _get_profile():\n",
        "    p = GAMIFICATION_REF.get() or {}\n",
        "\n",
        "    prof = {\n",
        "        \"points\": int(p.get(\"points\", DEFAULT_PROFILE[\"points\"])),\n",
        "        \"spins_available\": int(p.get(\"spins_available\", DEFAULT_PROFILE[\"spins_available\"])),\n",
        "        \"missions\": p.get(\"missions\", {}) or {},\n",
        "        \"coupons\": p.get(\"coupons\", []) or [],\n",
        "    }\n",
        "\n",
        "    # Merge default missions safely (ensures all mission keys exist)\n",
        "    merged = {}\n",
        "    for mid, base in DEFAULT_PROFILE[\"missions\"].items():\n",
        "        m = (prof[\"missions\"].get(mid) or {})\n",
        "        merged[mid] = {\n",
        "            \"last_completed\": m.get(\"last_completed\", base[\"last_completed\"]),\n",
        "            \"total_completed\": int(m.get(\"total_completed\", base[\"total_completed\"])),\n",
        "        }\n",
        "    prof[\"missions\"] = merged\n",
        "    return prof\n",
        "\n",
        "def _save_profile(prof: dict):\n",
        "    GAMIFICATION_REF.set(prof)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 5) Mission Completion Rule (Once per Day)\n",
        "#    - Adds points + 1 spin if not completed today\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def complete_mission(mission_id: str, points: int):\n",
        "    \"\"\"\n",
        "    Returns: (prof, earned_today: bool)\n",
        "    Logic: once-per-day per mission to prevent spam clicking.\n",
        "    Reward: +points AND +1 spin token.\n",
        "    \"\"\"\n",
        "    prof = _get_profile()\n",
        "    today = _today_key()\n",
        "\n",
        "    m = prof[\"missions\"].get(mission_id, {\"last_completed\": None, \"total_completed\": 0})\n",
        "    if m.get(\"last_completed\") == today:\n",
        "        return prof, False\n",
        "\n",
        "    prof[\"points\"] = int(prof.get(\"points\", 0)) + int(points)\n",
        "    prof[\"spins_available\"] = int(prof.get(\"spins_available\", 0)) + 1\n",
        "\n",
        "    m[\"last_completed\"] = today\n",
        "    m[\"total_completed\"] = int(m.get(\"total_completed\", 0)) + 1\n",
        "    prof[\"missions\"][mission_id] = m\n",
        "\n",
        "    _save_profile(prof)\n",
        "    return prof, True\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 6) Wheel Rewards (Spin Logic)\n",
        "#    - Consumes 1 spin token and grants points/coupon\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "WHEEL_REWARDS = [\n",
        "    (\"+5 points\",  {\"points\": 5}),\n",
        "    (\"+10 points\", {\"points\": 10}),\n",
        "    (\"+20 points\", {\"points\": 20}),\n",
        "    (\"Coupon: 5% off\",  {\"coupon\": {\"base\": \"CG-5OFF\", \"label\": \"5% off\"}}),\n",
        "    (\"Coupon: 10% off\", {\"coupon\": {\"base\": \"CG-10OFF\",\"label\": \"10% off\"}}),\n",
        "]\n",
        "\n",
        "def spin_wheel():\n",
        "    \"\"\"\n",
        "    Consumes 1 spin token and gives either points or a coupon.\n",
        "    Returns: (message, prof)\n",
        "    \"\"\"\n",
        "    prof = _get_profile()\n",
        "    spins = int(prof.get(\"spins_available\", 0))\n",
        "    if spins <= 0:\n",
        "        return \"No spins available. Complete a mission to earn a spin!\", prof\n",
        "\n",
        "    prof[\"spins_available\"] = spins - 1\n",
        "\n",
        "    label, payload = random.choice(WHEEL_REWARDS)\n",
        "\n",
        "    if \"points\" in payload:\n",
        "        prof[\"points\"] = int(prof.get(\"points\", 0)) + int(payload[\"points\"])\n",
        "\n",
        "    if \"coupon\" in payload:\n",
        "        # Make coupon code unique (so you can redeem multiple coupons)\n",
        "        from datetime import datetime\n",
        "        from zoneinfo import ZoneInfo\n",
        "        suffix = datetime.now(ZoneInfo(TZ_NAME)).strftime(\"%H%M%S\")\n",
        "        code = f\"{payload['coupon']['base']}-{suffix}\"\n",
        "\n",
        "        prof[\"coupons\"].append({\n",
        "            \"code\": code,\n",
        "            \"label\": payload[\"coupon\"][\"label\"],\n",
        "            \"created_at\": _now_iso(),\n",
        "            \"redeemed\": False,\n",
        "        })\n",
        "\n",
        "    _save_profile(prof)\n",
        "    return f\"üé° You got: {label}\", prof\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 7) Voucher Redemption by Points (Redeem Logic)\n",
        "#    - User chooses a tier, points are deducted, voucher created\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "REDEEM_TIERS = {\n",
        "    \"5‚Ç™ Voucher (100 pts)\": 100,\n",
        "    \"10‚Ç™ Voucher (200 pts)\": 200,\n",
        "    \"20‚Ç™ Voucher (350 pts)\": 350,\n",
        "}\n",
        "\n",
        "def redeem_voucher(tier_label: str):\n",
        "    \"\"\"\n",
        "    On Redeem click:\n",
        "    - If enough points: subtract cost, create voucher (coupon) and save to Firebase.\n",
        "    - Else: return message only.\n",
        "    Returns: (message, prof)\n",
        "    \"\"\"\n",
        "    prof = _get_profile()\n",
        "\n",
        "    if tier_label not in REDEEM_TIERS:\n",
        "        return \"Please select a voucher tier.\", prof\n",
        "\n",
        "    cost = int(REDEEM_TIERS[tier_label])\n",
        "    if int(prof.get(\"points\", 0)) < cost:\n",
        "        missing = cost - int(prof.get(\"points\", 0))\n",
        "        return f\"Not enough points. You need {missing} more.\", prof\n",
        "\n",
        "    # Create a simple unique voucher code\n",
        "    suffix = datetime.now(ZoneInfo(TZ_NAME)).strftime(\"%H%M%S\")\n",
        "    code = f\"VOUCH-{suffix}\"\n",
        "\n",
        "    prof[\"points\"] = int(prof.get(\"points\", 0)) - cost\n",
        "    prof[\"coupons\"].append({\n",
        "        \"code\": code,\n",
        "        \"label\": tier_label.split(\" (\")[0],  # \"5‚Ç™ Voucher\"\n",
        "        \"created_at\": _now_iso(),\n",
        "        \"redeemed\": True,  # since user redeemed it now\n",
        "    })\n",
        "\n",
        "    _save_profile(prof)\n",
        "    return f\"‚úÖ Voucher created! Code: {code}\", prof\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 8) Formatting Helpers (for UI display)\n",
        "#    - Converts profile data into nice text/markdown\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def _format_missions_md(prof: dict) -> str:\n",
        "    today = _today_key()\n",
        "    m = prof.get(\"missions\", {}) or {}\n",
        "\n",
        "    def row(mid, title):\n",
        "        last = (m.get(mid, {}) or {}).get(\"last_completed\")\n",
        "        total = (m.get(mid, {}) or {}).get(\"total_completed\", 0)\n",
        "        done = (last == today)\n",
        "        return f\"- **{title}**: {'‚úÖ Done today' if done else '‚¨ú Not done today'} (total: {total})\"\n",
        "\n",
        "    lines = [\n",
        "        \"### Daily Missions\",\n",
        "        row(\"sync_data\", \"Sync New Data\"),\n",
        "        row(\"analyze_plant\", \"Analyze a Plant Image\"),\n",
        "        row(\"generate_report\", \"Generate a Report\"),\n",
        "    ]\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def _format_coupons_text(prof: dict) -> str:\n",
        "    coupons = prof.get(\"coupons\", []) or []\n",
        "    if not coupons:\n",
        "        return \"No coupons yet.\"\n",
        "\n",
        "    lines = []\n",
        "    for c in coupons[-15:][::-1]:\n",
        "        status = \"REDEEMED\" if c.get(\"redeemed\") else \"ACTIVE\"\n",
        "        lines.append(f\"{c.get('code')} | {c.get('label','Coupon')} | {status}\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 9) UI Handlers (Gradio outputs)\n",
        "#    - Functions that return values matching Gradio outputs\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def rewards_refresh():\n",
        "    prof = _get_profile()\n",
        "    return (\n",
        "        str(prof.get(\"points\", 0)),\n",
        "        str(prof.get(\"spins_available\", 0)),\n",
        "        _format_missions_md(prof),\n",
        "        _format_coupons_text(prof),\n",
        "    )\n",
        "\n",
        "def rewards_spin():\n",
        "    msg, _ = spin_wheel()\n",
        "    pts, spins, missions_md, coupons_txt = rewards_refresh()\n",
        "    return msg, pts, spins, missions_md, coupons_txt\n",
        "\n",
        "def rewards_redeem(tier_label: str):\n",
        "    msg, _ = redeem_voucher(tier_label)\n",
        "    pts, spins, missions_md, coupons_txt = rewards_refresh()\n",
        "    return msg, pts, spins, missions_md, coupons_txt\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 10) Mission Wrappers (connect app actions -> mission rewards)\n",
        "#     - Wrap existing app functions and award missions if valid\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def sync_screen_gamified():\n",
        "    msg, count = sync_new_data_from_server()\n",
        "    # Mission completed only if new rows were actually saved\n",
        "    if count and count > 0:\n",
        "        prof, earned = complete_mission(\"sync_data\", points=10)\n",
        "        if earned:\n",
        "            msg += f\"\\nüéÆ Rewards: +10 points, +1 spin (Spins now: {prof['spins_available']})\"\n",
        "    return msg\n",
        "\n",
        "def analyze_plant_gamified(image, temp, humidity, soil):\n",
        "    diagnosis, status_html, alerts, recommendations = analyze_plant(image, temp, humidity, soil)\n",
        "\n",
        "    # Mission completed only if an image was actually provided\n",
        "    if image:\n",
        "        prof, earned = complete_mission(\"analyze_plant\", points=8)\n",
        "        if earned:\n",
        "            recommendations = (recommendations or \"\")\n",
        "            recommendations += f\"\\n\\nüéÆ Rewards: +8 points, +1 spin (Spins now: {prof['spins_available']})\"\n",
        "\n",
        "    return diagnosis, status_html, alerts, recommendations\n",
        "\n",
        "def generate_report_screen_gamified(limit: int):\n",
        "    status, file_path = generate_report_screen(limit)\n",
        "    # Mission completed only if report file was actually generated\n",
        "    if file_path:\n",
        "        prof, earned = complete_mission(\"generate_report\", points=12)\n",
        "        if earned:\n",
        "            status += f\" | üéÆ +12 points, +1 spin (Spins now: {prof['spins_available']})\"\n",
        "    return status, file_path\n"
      ],
      "metadata": {
        "id": "cYezmE4LkuuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ APP BUILDER"
      ],
      "metadata": {
        "id": "9MAtxIWckkZ7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEj9G-EnMWTN"
      },
      "outputs": [],
      "source": [
        "def build_placeholder_tab(title: str, note: str = \"◊õ◊ê◊ü ◊ô◊ô◊õ◊†◊° ◊î◊ß◊ï◊ì ◊ë◊î◊û◊©◊ö\"):\n",
        "    gr.Markdown(f\"## {title}\")\n",
        "    gr.Markdown(note)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# TABS (EMPTY PLACEHOLDERS)\n",
        "# -----------------------------\n",
        "\n",
        "def build_iot_dashboard_tab():\n",
        "    \"\"\"Complete IoT Dashboard with all visualizations\"\"\"\n",
        "\n",
        "    gr.Markdown('### üìà Comprehensive Sensor Analytics')\n",
        "\n",
        "    refresh_btn = gr.Button('üîÑ Refresh All Data', variant='primary', size='lg')\n",
        "\n",
        "    # KPI Cards\n",
        "    gr.Markdown('#### üìå Current Readings')\n",
        "    kpi_html = gr.HTML()\n",
        "\n",
        "    # Statistics Cards\n",
        "    gr.Markdown('#### üìä Statistical Summary')\n",
        "    stats_html = gr.HTML()\n",
        "\n",
        "    # Main Time Series\n",
        "    gr.Markdown('#### üìà Time Series Overview')\n",
        "    ts_plot = gr.Plot()\n",
        "\n",
        "    # Correlation Analysis\n",
        "    gr.Markdown('#### üîó Correlation Analysis')\n",
        "    corr_card = gr.HTML()\n",
        "    corr_plot = gr.Plot()\n",
        "\n",
        "    # Hourly Patterns\n",
        "    gr.Markdown('#### ‚è∞ Hourly Patterns')\n",
        "    hourly_card = gr.HTML()\n",
        "    hourly_plot = gr.Plot()\n",
        "\n",
        "    # Daily Trends\n",
        "    gr.Markdown('#### üìÖ Daily Trends')\n",
        "    daily_card = gr.HTML()\n",
        "    daily_plot = gr.Plot()\n",
        "\n",
        "    # Distribution Analysis\n",
        "    gr.Markdown('#### üìä Distribution Analysis (Histograms)')\n",
        "    dist_card = gr.HTML()\n",
        "    dist_plot = gr.Plot()\n",
        "\n",
        "    # Moving Averages\n",
        "    gr.Markdown('#### üìâ Moving Averages')\n",
        "    with gr.Row():\n",
        "        ma_variable = gr.Dropdown(\n",
        "            choices=['temperature', 'humidity', 'soil'],\n",
        "            value='temperature',\n",
        "            label='Select Variable'\n",
        "        )\n",
        "        ma_btn = gr.Button('Generate Moving Average')\n",
        "    ma_card = gr.HTML()\n",
        "    ma_plot = gr.Plot()\n",
        "\n",
        "    # Wire up refresh button (11 outputs - without scatter)\n",
        "    refresh_btn.click(\n",
        "        dashboard_screen,\n",
        "        outputs=[\n",
        "            kpi_html, stats_html, ts_plot,\n",
        "            corr_card, corr_plot,\n",
        "            hourly_card, hourly_plot,\n",
        "            daily_card, daily_plot,\n",
        "            dist_card, dist_plot\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Wire up moving average\n",
        "    ma_btn.click(\n",
        "        dashboard_moving_avg,\n",
        "        inputs=ma_variable,\n",
        "        outputs=[ma_card, ma_plot]\n",
        "    )\n",
        "\n",
        "\n",
        "def build_search_engine_tab():\n",
        "    build_placeholder_tab(\"üîç Search Engine\")\n",
        "\n",
        "#def build_rag_chat_tab():\n",
        " #   build_placeholder_tab(\"üí¨ RAG Chat\")\n",
        "\n",
        "def build_sync_data_tab():\n",
        "    \"\"\"Sync data from server to Firebase\"\"\"\n",
        "\n",
        "    gr.Markdown('Sync Data from to Server')\n",
        "    gr.Markdown('Upload IoT Data to FireBase')\n",
        "\n",
        "    sync_btn = gr.Button('üîÑ Sync New Data', variant='primary', size='lg')\n",
        "    sync_output = gr.Textbox(label='Status', lines=5)\n",
        "\n",
        "    sync_btn.click(sync_screen_gamified, outputs=sync_output)\n",
        "\n",
        "def build_rewards_tab():\n",
        "    # ---------------------------------------------------------\n",
        "    # 1) Load current profile snapshot (initial values)\n",
        "    # ---------------------------------------------------------\n",
        "    prof = _get_profile()\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 2) Title + short explanation\n",
        "    # ---------------------------------------------------------\n",
        "    gr.Markdown(\"## üéÆ Farm Rewards\")\n",
        "    gr.Markdown(\n",
        "        \"Complete daily missions to earn points and **1 spin per mission**. \"\n",
        "        \"Spin the wheel to win bonus points or vouchers (demo).\"\n",
        "    )\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 3) KPI section (Points + Spins)\n",
        "    # ---------------------------------------------------------\n",
        "    with gr.Row():\n",
        "        points_box = gr.Textbox(\n",
        "            label=\"Points\",\n",
        "            value=str(prof.get(\"points\", 0)),\n",
        "            interactive=False\n",
        "        )\n",
        "        spins_box = gr.Textbox(\n",
        "            label=\"Spins available\",\n",
        "            value=str(prof.get(\"spins_available\", 0)),\n",
        "            interactive=False\n",
        "        )\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 4) Missions + Vouchers display\n",
        "    # ---------------------------------------------------------\n",
        "    missions_md = gr.Markdown(_format_missions_md(prof))\n",
        "    coupons_txt = gr.Textbox(\n",
        "        label=\"Vouchers\",\n",
        "        value=_format_coupons_text(prof),\n",
        "        lines=7,\n",
        "        interactive=False\n",
        "    )\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 5) Actions: Refresh + Spin\n",
        "    # ---------------------------------------------------------\n",
        "    with gr.Row():\n",
        "        refresh_btn = gr.Button(\"üîÑ Refresh\", variant=\"secondary\")\n",
        "        spin_btn = gr.Button(\"üé° Spin the Wheel\", variant=\"primary\")\n",
        "\n",
        "    spin_result = gr.Textbox(\n",
        "        label=\"Spin result\",\n",
        "        lines=2,\n",
        "        interactive=False\n",
        "    )\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 6) Redeem voucher by points (tier selection)\n",
        "    # ---------------------------------------------------------\n",
        "    gr.Markdown(\"### Redeem a Voucher\")\n",
        "\n",
        "    tier = gr.Dropdown(\n",
        "        choices=list(REDEEM_TIERS.keys()),\n",
        "        label=\"Select voucher tier\",\n",
        "        value=\"5‚Ç™ Voucher (100 pts)\"\n",
        "    )\n",
        "\n",
        "    redeem_btn = gr.Button(\"üéüÔ∏è Redeem\", variant=\"primary\")\n",
        "\n",
        "    redeem_result = gr.Textbox(\n",
        "        label=\"Redeem status\",\n",
        "        lines=2,\n",
        "        interactive=False\n",
        "    )\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 7) Wiring (connect buttons -> LOGIC handlers)\n",
        "    # ---------------------------------------------------------\n",
        "    refresh_btn.click(\n",
        "        fn=rewards_refresh,\n",
        "        outputs=[points_box, spins_box, missions_md, coupons_txt]\n",
        "    )\n",
        "\n",
        "    spin_btn.click(\n",
        "        fn=rewards_spin,\n",
        "        outputs=[spin_result, points_box, spins_box, missions_md, coupons_txt]\n",
        "    )\n",
        "\n",
        "    redeem_btn.click(\n",
        "        fn=rewards_redeem,\n",
        "        inputs=[tier],\n",
        "        outputs=[redeem_result, points_box, spins_box, missions_md, coupons_txt]\n",
        "    )\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 8) Return component refs (for build_app auto-refresh)\n",
        "    # ---------------------------------------------------------\n",
        "    return points_box, spins_box, missions_md, coupons_txt\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFEXSm_SUr4-"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ ◊®◊©◊ô◊û◊™ ◊î◊ò◊ê◊ë◊ô◊ù ‚Äî ◊ñ◊î ◊î◊û◊ß◊ï◊ù ◊î◊ô◊ó◊ô◊ì ◊©◊û◊ï◊°◊ô◊§◊ô◊ù/◊û◊ï◊®◊ô◊ì◊ô◊ù ◊ò◊ê◊ë◊ô◊ù\n",
        "TABS = [\n",
        "    (\"üå± Realtime Dashboard\", build_realtime_dashboard_tab),\n",
        "    (\"üìä Analistic Dashboard\", build_iot_dashboard_tab),\n",
        "    (\"üìÑ Generate Report\", build_generate_report_tab),\n",
        "    (\"üñºÔ∏è Plant Disease Detection\", build_plant_disease_detection_tab),\n",
        "    (\"üí¨ RAG Chat\", build_rag_chat_tab),\n",
        "    (\"üîÑ Sync Data\", build_sync_data_tab),\n",
        "    (\"üéÆ Farm Rewards\", build_rewards_tab),\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33OVXQN6PXGG"
      },
      "source": [
        "## üìà Visualization Functions (Analistic Dashboard)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHqZANXcPWCB"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# Cell 7: Complete Visualization Functions (WITHOUT SCATTER ANALYSIS)\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import numpy as np\n",
        "\n",
        "# Sensor configuration\n",
        "SENSORS = [\n",
        "    ('temperature', '¬∞C', COLORS['temperature']['color'], COLORS['temperature']['color'], 'TEMPERATURE'),\n",
        "    ('humidity', '%', COLORS['humidity']['color'], COLORS['humidity']['color'], 'HUMIDITY'),\n",
        "    ('soil', '%', COLORS['soil']['color'], COLORS['soil']['color'], 'SOIL MOISTURE')\n",
        "]\n",
        "print('‚úì Sensor config loaded')\n",
        "\n",
        "# ============================================================================\n",
        "# COMPONENT FUNCTIONS\n",
        "# ============================================================================\n",
        "def create_kpi_card(label, value, unit, change, change_label, trend=\"up\", border_color=None):\n",
        "    \"\"\"Create KPI card HTML.\"\"\"\n",
        "    bc = border_color or COLORS['temperature']['color']\n",
        "    icon = \"‚Üë\" if trend == \"up\" else (\"‚Üì\" if trend == \"down\" else \"‚Üí\")\n",
        "    return f'''<div class=\"kpi-card\" style=\"border-left-color: {bc};\">\n",
        "        <p class=\"kpi-label\">{label}</p>\n",
        "        <p class=\"kpi-value\">{value}<span style=\"font-size: 24px;\">{unit}</span></p>\n",
        "        <p class=\"kpi-change trend-{trend}\"><span>{icon}</span><span>{change} {change_label}</span></p>\n",
        "    </div>'''\n",
        "\n",
        "def create_status_badge(text=\"LIVE\", pulse=True):\n",
        "    \"\"\"Create status badge HTML.\"\"\"\n",
        "    pulse_dot = \"<span class='status-dot'></span>\" if pulse else \"\"\n",
        "    return f'<span class=\"status-badge\">{pulse_dot}{text}</span>'\n",
        "\n",
        "def create_explanation_card(title, description, interpretation, gradient=None):\n",
        "    \"\"\"Create explanation card HTML.\"\"\"\n",
        "    grad = gradient or COLORS['temperature']['color']\n",
        "    return f'''<div class=\"explanation-card\" style=\"background: {grad};\">\n",
        "        <h3>üìä {title}</h3><p><strong>What it shows:</strong> {description}</p>\n",
        "        <p><strong>How to interpret:</strong> {interpretation}</p></div>'''\n",
        "\n",
        "print('‚úì Component functions loaded')\n",
        "\n",
        "# ============================================================================\n",
        "# STATISTICS CARDS\n",
        "# ============================================================================\n",
        "def create_stat_cards_html(df):\n",
        "    \"\"\"Create comprehensive statistics cards for all sensors.\"\"\"\n",
        "    if len(df) == 0:\n",
        "        return \"<p>No data available</p>\"\n",
        "\n",
        "    explanations = {\n",
        "        'Mean': 'Average value. Sum √∑ count.',\n",
        "        'Median': 'Middle value. 50% above, 50% below.',\n",
        "        'Std Dev': 'Variability around mean. Low=consistent, High=variable.',\n",
        "        'Min': 'Lowest recorded value.',\n",
        "        'Max': 'Highest recorded value.',\n",
        "        'Q25': '25th percentile. 25% below this.',\n",
        "        'Q75': '75th percentile. 75% below this.',\n",
        "        'IQR': 'Interquartile range (Q75-Q25).'\n",
        "    }\n",
        "\n",
        "    sensor_colors = {\n",
        "        'TEMPERATURE': {'bg': '#fee2e2', 'text': '#991b1b', 'border': '#ef4444'},\n",
        "        'HUMIDITY': {'bg': '#dbeafe', 'text': '#1e40af', 'border': '#3b82f6'},\n",
        "        'SOIL MOISTURE': {'bg': '#e9d5ff', 'text': '#6b21a8', 'border': '#8b5cf6'}\n",
        "    }\n",
        "\n",
        "    html = '<div style=\"display: grid; grid-template-columns: repeat(3, 1fr); gap: 16px; margin: 20px 0;\">'\n",
        "\n",
        "    for var, unit, _, _, name in SENSORS:\n",
        "        stats = {k: round(v, 2) for k, v in {\n",
        "            'Mean': df[var].mean(),\n",
        "            'Median': df[var].median(),\n",
        "            'Std Dev': df[var].std(),\n",
        "            'Min': df[var].min(),\n",
        "            'Max': df[var].max(),\n",
        "            'Q25': df[var].quantile(0.25),\n",
        "            'Q75': df[var].quantile(0.75),\n",
        "            'IQR': df[var].quantile(0.75) - df[var].quantile(0.25)\n",
        "        }.items()}\n",
        "\n",
        "        colors = sensor_colors[name]\n",
        "\n",
        "        html += f'''\n",
        "        <div style=\"\n",
        "            background: {colors['bg']};\n",
        "            border: 3px solid {colors['border']};\n",
        "            border-radius: 12px;\n",
        "            padding: 20px;\n",
        "            box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
        "        \">\n",
        "            <h2 style=\"\n",
        "                color: {colors['text']};\n",
        "                margin: 0 0 16px 0;\n",
        "                font-size: 20px;\n",
        "                font-weight: 700;\n",
        "                text-align: center;\n",
        "            \">{name}</h2>\n",
        "            <div style=\"display: grid; grid-template-columns: repeat(2, 1fr); gap: 12px;\">\n",
        "        '''\n",
        "\n",
        "        for stat_name, stat_val in stats.items():\n",
        "            html += f'''\n",
        "            <div style=\"\n",
        "                background: white;\n",
        "                border-radius: 8px;\n",
        "                padding: 12px;\n",
        "                box-shadow: 0 1px 3px rgba(0,0,0,0.1);\n",
        "            \">\n",
        "                <div style=\"\n",
        "                    display: flex;\n",
        "                    justify-content: space-between;\n",
        "                    align-items: center;\n",
        "                    margin-bottom: 4px;\n",
        "                \">\n",
        "                    <div style=\"\n",
        "                        font-size: 12px;\n",
        "                        font-weight: 600;\n",
        "                        color: {colors['text']};\n",
        "                    \">{stat_name}</div>\n",
        "                    <div class=\"info-icon\" style=\"\n",
        "                        width: 18px;\n",
        "                        height: 18px;\n",
        "                        border-radius: 50%;\n",
        "                        background: {colors['border']};\n",
        "                        color: white;\n",
        "                        display: flex;\n",
        "                        align-items: center;\n",
        "                        justify-content: center;\n",
        "                        font-size: 11px;\n",
        "                        font-weight: 700;\n",
        "                    \">i\n",
        "                        <span class=\"tooltip-text\">{explanations[stat_name]}</span>\n",
        "                    </div>\n",
        "                </div>\n",
        "                <div style=\"\n",
        "                    font-size: 24px;\n",
        "                    font-weight: 700;\n",
        "                    color: {colors['text']};\n",
        "                \">{stat_val}{unit}</div>\n",
        "            </div>\n",
        "            '''\n",
        "\n",
        "        html += '</div></div>'\n",
        "\n",
        "    html += '</div>'\n",
        "    return html\n",
        "\n",
        "print('‚úì Statistics functions loaded')\n",
        "\n",
        "# ============================================================================\n",
        "# CHART STYLING\n",
        "# ============================================================================\n",
        "def apply_chart_styling(fig, title=\"\", xaxis_title=\"\", yaxis_title=\"\", height=400):\n",
        "    \"\"\"Apply consistent styling to all charts.\"\"\"\n",
        "    fig.update_layout(\n",
        "        title=dict(text=title, font=dict(size=20)),\n",
        "        xaxis_title=xaxis_title,\n",
        "        yaxis_title=yaxis_title,\n",
        "        font=dict(family=\"Inter, sans-serif\", size=14),\n",
        "        plot_bgcolor='white',\n",
        "        paper_bgcolor='white',\n",
        "        height=height,\n",
        "        hovermode='x unified'\n",
        "    )\n",
        "    fig.update_xaxes(showgrid=False, title_font=dict(size=14, color='#6b7280'), tickfont=dict(size=12))\n",
        "    fig.update_yaxes(showgrid=True, gridcolor='#E5E7EB', title_font=dict(size=14, color='#6b7280'), tickfont=dict(size=12))\n",
        "    return fig\n",
        "\n",
        "print('‚úì Chart styling loaded')\n",
        "\n",
        "# ============================================================================\n",
        "# PLOT FUNCTIONS\n",
        "# ============================================================================\n",
        "def time_series_overview(df):\n",
        "    \"\"\"Time series for all sensors.\"\"\"\n",
        "    fig = go.Figure()\n",
        "    for col, unit, color, _, _ in SENSORS:\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=df['timestamp'],\n",
        "            y=df[col],\n",
        "            name=col.capitalize(),\n",
        "            mode='lines',\n",
        "            line=dict(color=color, width=2),\n",
        "            hovertemplate=f'%{{y:.1f}}{unit}<extra></extra>'\n",
        "        ))\n",
        "    apply_chart_styling(fig, \"Sensor Data Time Series\", \"Time\", \"Measurement (¬∞C / %)\", 500)\n",
        "    return create_explanation_card(\n",
        "        \"Time Series Overview\",\n",
        "        \"All sensor measurements over time.\",\n",
        "        \"Look for trends, cycles, and sudden changes.\"\n",
        "    ), fig\n",
        "\n",
        "def calculate_correlations(df):\n",
        "    \"\"\"Correlation matrix between sensors.\"\"\"\n",
        "    corr = df[['temperature', 'humidity', 'soil']].corr()\n",
        "    fig = px.imshow(\n",
        "        corr,\n",
        "        labels=dict(color=\"Correlation\"),\n",
        "        x=['Temperature', 'Humidity', 'Soil'],\n",
        "        y=['Temperature', 'Humidity', 'Soil'],\n",
        "        color_continuous_scale='RdBu_r',\n",
        "        zmin=-1,\n",
        "        zmax=1,\n",
        "        aspect=\"auto\"\n",
        "    )\n",
        "    apply_chart_styling(fig, \"Correlation Matrix\", \"Variables\", \"Variables\", 500)\n",
        "\n",
        "    # Add correlation values\n",
        "    for i in range(len(corr)):\n",
        "        for j in range(len(corr)):\n",
        "            fig.add_annotation(\n",
        "                x=j, y=i,\n",
        "                text=str(round(corr.iloc[i, j], 3)),\n",
        "                showarrow=False,\n",
        "                font=dict(size=14, color='black' if abs(corr.iloc[i, j]) < 0.5 else 'white', weight=600)\n",
        "            )\n",
        "\n",
        "    return create_explanation_card(\n",
        "        \"Correlation Analysis\",\n",
        "        \"Linear relationships between sensors. +1=perfect positive, -1=perfect negative, 0=no relationship.\",\n",
        "        \"High correlations indicate sensors respond together.\",\n",
        "        COLORS['humidity']['color']\n",
        "    ), fig\n",
        "\n",
        "def hourly_patterns(df):\n",
        "    \"\"\"Average values by hour of day.\"\"\"\n",
        "    df_copy = df.copy()\n",
        "    df_copy['hour'] = df_copy['timestamp'].dt.hour\n",
        "    hourly = df_copy.groupby('hour')[['temperature', 'humidity', 'soil']].mean()\n",
        "\n",
        "    fig = go.Figure()\n",
        "    for col, _, color, _, _ in SENSORS:\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=hourly.index,\n",
        "            y=hourly[col],\n",
        "            name=col.capitalize(),\n",
        "            mode='lines+markers',\n",
        "            line=dict(color=color, width=2.5),\n",
        "            marker=dict(size=8)\n",
        "        ))\n",
        "\n",
        "    apply_chart_styling(fig, \"Average Values by Hour\", \"Hour (0-23)\", \"Average Measurement (¬∞C / %)\", 450)\n",
        "    return create_explanation_card(\n",
        "        \"Hourly Patterns\",\n",
        "        \"Average values per hour showing daily cycles.\",\n",
        "        \"Look for peaks and valleys that repeat daily.\",\n",
        "        COLORS['soil']['color']\n",
        "    ), fig\n",
        "\n",
        "def daily_patterns(df):\n",
        "    \"\"\"Daily trends with min-max ranges.\"\"\"\n",
        "    df_copy = df.copy()\n",
        "    df_copy['date'] = df_copy['timestamp'].dt.date\n",
        "    daily = df_copy.groupby('date')[['temperature', 'humidity', 'soil']].agg(['mean', 'min', 'max'])\n",
        "\n",
        "    fig = make_subplots(\n",
        "        rows=3, cols=1,\n",
        "        subplot_titles=('Temperature (¬∞C)', 'Humidity (%)', 'Soil (%)'),\n",
        "        vertical_spacing=0.08\n",
        "    )\n",
        "\n",
        "    for idx, (var, _, color, _, _) in enumerate(SENSORS, 1):\n",
        "        dates = [str(d) for d in daily.index]\n",
        "        r, g, b = int(color[1:3], 16), int(color[3:5], 16), int(color[5:7], 16)\n",
        "\n",
        "        # Min-max range\n",
        "        fig.add_trace(go.Scatter(x=dates, y=daily[var]['max'], mode='lines', line=dict(width=0), showlegend=False, hoverinfo='skip'), row=idx, col=1)\n",
        "        fig.add_trace(go.Scatter(x=dates, y=daily[var]['min'], mode='lines', line=dict(width=0),\n",
        "                                fill='tonexty', fillcolor=f\"rgba({r},{g},{b},0.2)\", showlegend=False, hoverinfo='skip'), row=idx, col=1)\n",
        "\n",
        "        # Mean line\n",
        "        fig.add_trace(go.Scatter(x=dates, y=daily[var]['mean'], mode='lines+markers',\n",
        "                                line=dict(color=color, width=2.5), marker=dict(size=6), name='Mean', showlegend=(idx==1)), row=idx, col=1)\n",
        "\n",
        "    fig.update_xaxes(title_text=\"Date\", row=3, col=1)\n",
        "    fig.update_yaxes(title_text=\"Temperature (¬∞C)\", row=1, col=1)\n",
        "    fig.update_yaxes(title_text=\"Humidity (%)\", row=2, col=1)\n",
        "    fig.update_yaxes(title_text=\"Soil Moisture (%)\", row=3, col=1)\n",
        "    fig.update_layout(height=900)\n",
        "\n",
        "    return create_explanation_card(\n",
        "        \"Daily Trends\",\n",
        "        \"Daily means with min-max ranges (shaded).\",\n",
        "        \"Wider shading = more variability. Look for trends and unusual days.\"\n",
        "    ), fig\n",
        "\n",
        "def distribution_analysis(df):\n",
        "    \"\"\"Histograms showing distribution of sensor values.\"\"\"\n",
        "    fig = make_subplots(\n",
        "        rows=1, cols=3,\n",
        "        subplot_titles=('Temperature (¬∞C)', 'Humidity (%)', 'Soil Moisture (%)')\n",
        "    )\n",
        "\n",
        "    # Temperature histogram\n",
        "    temp_data = df['temperature'].values\n",
        "    temp_min, temp_max = temp_data.min(), temp_data.max()\n",
        "    temp_padding = (temp_max - temp_min) * 0.1\n",
        "    temp_bins = np.linspace(temp_min - temp_padding, temp_max + temp_padding, 31)\n",
        "    temp_counts, temp_edges = np.histogram(temp_data, bins=temp_bins)\n",
        "    temp_centers = (temp_edges[:-1] + temp_edges[1:]) / 2\n",
        "\n",
        "    fig.add_trace(go.Bar(\n",
        "        x=temp_centers,\n",
        "        y=temp_counts,\n",
        "        name='Temperature',\n",
        "        marker_color=COLORS['temperature']['color'],\n",
        "        width=(temp_max - temp_min) / 30 * 0.9,\n",
        "        hovertemplate='%{x:.1f}¬∞C: %{y} readings<extra></extra>'\n",
        "    ), row=1, col=1)\n",
        "\n",
        "    # Humidity histogram\n",
        "    humidity_data = df['humidity'].values\n",
        "    humidity_min, humidity_max = humidity_data.min(), humidity_data.max()\n",
        "    humidity_padding = (humidity_max - humidity_min) * 0.1\n",
        "    humidity_bins = np.linspace(humidity_min - humidity_padding, humidity_max + humidity_padding, 31)\n",
        "    humidity_counts, humidity_edges = np.histogram(humidity_data, bins=humidity_bins)\n",
        "    humidity_centers = (humidity_edges[:-1] + humidity_edges[1:]) / 2\n",
        "\n",
        "    fig.add_trace(go.Bar(\n",
        "        x=humidity_centers,\n",
        "        y=humidity_counts,\n",
        "        name='Humidity',\n",
        "        marker_color=COLORS['humidity']['color'],\n",
        "        width=(humidity_max - humidity_min) / 30 * 0.9,\n",
        "        hovertemplate='%{x:.1f}%: %{y} readings<extra></extra>'\n",
        "    ), row=1, col=2)\n",
        "\n",
        "    # Soil histogram\n",
        "    soil_data = df['soil'].values\n",
        "    soil_min, soil_max = soil_data.min(), soil_data.max()\n",
        "    soil_padding = (soil_max - soil_min) * 0.1\n",
        "    soil_bins = np.linspace(soil_min - soil_padding, soil_max + soil_padding, 31)\n",
        "    soil_counts, soil_edges = np.histogram(soil_data, bins=soil_bins)\n",
        "    soil_centers = (soil_edges[:-1] + soil_edges[1:]) / 2\n",
        "\n",
        "    fig.add_trace(go.Bar(\n",
        "        x=soil_centers,\n",
        "        y=soil_counts,\n",
        "        name='Soil Moisture',\n",
        "        marker_color=COLORS['soil']['color'],\n",
        "        width=(soil_max - soil_min) / 30 * 0.9,\n",
        "        hovertemplate='%{x:.1f}%: %{y} readings<extra></extra>'\n",
        "    ), row=1, col=3)\n",
        "\n",
        "    # Configure axes\n",
        "    fig.update_xaxes(title_text=\"Temperature (¬∞C)\", row=1, col=1)\n",
        "    fig.update_xaxes(title_text=\"Humidity (%)\", row=1, col=2)\n",
        "    fig.update_xaxes(title_text=\"Soil Moisture (%)\", row=1, col=3)\n",
        "    fig.update_yaxes(title_text=\"Number of Readings\", row=1, col=1)\n",
        "    fig.update_yaxes(title_text=\"Number of Readings\", row=1, col=2)\n",
        "    fig.update_yaxes(title_text=\"Number of Readings\", row=1, col=3)\n",
        "\n",
        "    fig.update_layout(height=400, showlegend=False, plot_bgcolor='white', paper_bgcolor='white')\n",
        "\n",
        "    return create_explanation_card(\n",
        "        \"Distribution Analysis\",\n",
        "        \"Frequency of sensor values. Tall bars = common values, short bars = rare values.\",\n",
        "        \"Look for the shape: bell curve = normal, multiple peaks = different patterns.\",\n",
        "        COLORS['humidity']['color']\n",
        "    ), fig\n",
        "\n",
        "def time_series_decomposition(df, variable='temperature'):\n",
        "    \"\"\"Moving averages showing smoothed trends.\"\"\"\n",
        "    df_s = df.sort_values('timestamp').copy()\n",
        "\n",
        "    # Calculate moving averages with different windows\n",
        "    for window in [3, 10, 30]:\n",
        "        df_s[f'MA_{window}'] = df_s[variable].rolling(window, center=True).mean()\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Raw data\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=df_s['timestamp'],\n",
        "        y=df_s[variable],\n",
        "        name='Raw',\n",
        "        mode='lines',\n",
        "        line=dict(width=1, color='#4B5563'),\n",
        "        opacity=0.6\n",
        "    ))\n",
        "\n",
        "    # Moving averages\n",
        "    for ma, color, width in [('MA_3', '#10b981', 1.5), ('MA_10', '#3b82f6', 2.5), ('MA_30', '#ef4444', 3.5)]:\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=df_s['timestamp'],\n",
        "            y=df_s[ma],\n",
        "            name=ma,\n",
        "            line=dict(width=width, color=color)\n",
        "        ))\n",
        "\n",
        "    unit = '¬∞C' if variable == 'temperature' else '%'\n",
        "    apply_chart_styling(fig, f'Moving Averages - {variable.capitalize()}', 'Time', f'{variable.capitalize()} ({unit})', 450)\n",
        "\n",
        "    return create_explanation_card(\n",
        "        \"Moving Averages\",\n",
        "        \"Smoothed trends at different scales (3, 10, 30 measurements).\",\n",
        "        \"Thicker lines=longer windows=smoother trends.\"\n",
        "    ), fig\n",
        "\n",
        "# ============================================================================\n",
        "# DASHBOARD FUNCTIONS FOR GRADIO\n",
        "# ============================================================================\n",
        "\n",
        "def create_kpi_cards(df):\n",
        "    \"\"\"Create simple KPI cards for dashboard.\"\"\"\n",
        "    if df.empty:\n",
        "        return \"<div style='padding: 20px; text-align: center;'>◊ê◊ô◊ü ◊†◊™◊ï◊†◊ô◊ù ◊ñ◊û◊ô◊†◊ô◊ù</div>\"\n",
        "\n",
        "    latest = df.iloc[-1]\n",
        "\n",
        "    # Calculate trends\n",
        "    if len(df) > 10:\n",
        "        prev = df.iloc[-10]\n",
        "        temp_trend = \"up\" if latest['temperature'] > prev['temperature'] else \"down\" if latest['temperature'] < prev['temperature'] else \"stable\"\n",
        "        hum_trend = \"up\" if latest['humidity'] > prev['humidity'] else \"down\" if latest['humidity'] < prev['humidity'] else \"stable\"\n",
        "        soil_trend = \"up\" if latest['soil'] > prev['soil'] else \"down\" if latest['soil'] < prev['soil'] else \"stable\"\n",
        "\n",
        "        temp_change = f\"{abs(latest['temperature'] - prev['temperature']):.1f}\"\n",
        "        hum_change = f\"{abs(latest['humidity'] - prev['humidity']):.1f}\"\n",
        "        soil_change = f\"{abs(latest['soil'] - prev['soil']):.1f}\"\n",
        "    else:\n",
        "        temp_trend = hum_trend = soil_trend = \"stable\"\n",
        "        temp_change = hum_change = soil_change = \"0.0\"\n",
        "\n",
        "    # Create HTML\n",
        "    html = f\"\"\"\n",
        "    <div style=\"display: grid; grid-template-columns: repeat(3, 1fr); gap: 24px; margin: 20px 0;\">\n",
        "        {create_kpi_card('üå°Ô∏è Temperature', f'{latest[\"temperature\"]:.1f}', '¬∞C', temp_change, 'from last 10', temp_trend, COLORS['temperature']['color'])}\n",
        "        {create_kpi_card('üíß Humidity', f'{latest[\"humidity\"]:.1f}', '%', hum_change, 'from last 10', hum_trend, COLORS['humidity']['color'])}\n",
        "        {create_kpi_card('üå± Soil Moisture', f'{latest[\"soil\"]:.1f}', '%', soil_change, 'from last 10', soil_trend, COLORS['soil']['color'])}\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    return html\n",
        "\n",
        "def create_time_series_plot(df):\n",
        "    \"\"\"Create time series plot for dashboard.\"\"\"\n",
        "    if df.empty:\n",
        "        fig = go.Figure()\n",
        "        fig.add_annotation(\n",
        "            text=\"No data available\",\n",
        "            xref=\"paper\", yref=\"paper\",\n",
        "            x=0.5, y=0.5, showarrow=False,\n",
        "            font=dict(size=20)\n",
        "        )\n",
        "        fig.update_layout(height=500)\n",
        "        return fig\n",
        "\n",
        "    fig = make_subplots(\n",
        "        rows=3, cols=1,\n",
        "        subplot_titles=('üå°Ô∏è Temperature (¬∞C)', 'üíß Humidity (%)', 'üå± Soil Moisture (%)'),\n",
        "        vertical_spacing=0.08\n",
        "    )\n",
        "\n",
        "    # Temperature\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=df['timestamp'],\n",
        "            y=df['temperature'],\n",
        "            name='Temperature',\n",
        "            line=dict(color=COLORS['temperature']['color'], width=2),\n",
        "            fill='tozeroy',\n",
        "            fillcolor=f\"rgba(239, 68, 68, 0.1)\"\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    # Humidity\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=df['timestamp'],\n",
        "            y=df['humidity'],\n",
        "            name='Humidity',\n",
        "            line=dict(color=COLORS['humidity']['color'], width=2),\n",
        "            fill='tozeroy',\n",
        "            fillcolor=f\"rgba(59, 130, 246, 0.1)\"\n",
        "        ),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "    # Soil\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=df['timestamp'],\n",
        "            y=df['soil'],\n",
        "            name='Soil',\n",
        "            line=dict(color=COLORS['soil']['color'], width=2),\n",
        "            fill='tozeroy',\n",
        "            fillcolor=f\"rgba(139, 92, 246, 0.1)\"\n",
        "        ),\n",
        "        row=3, col=1\n",
        "    )\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_xaxes(showgrid=True, gridcolor='#E5E7EB')\n",
        "    fig.update_yaxes(showgrid=True, gridcolor='#E5E7EB')\n",
        "\n",
        "    fig.update_layout(\n",
        "        height=800,\n",
        "        showlegend=False,\n",
        "        plot_bgcolor='white',\n",
        "        paper_bgcolor='white',\n",
        "        font=dict(family=\"Inter, sans-serif\")\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "print('‚úÖ ALL visualization functions loaded!')\n",
        "print('   ‚úì Time Series')\n",
        "print('   ‚úì Correlations')\n",
        "print('   ‚úì Hourly/Daily Patterns')\n",
        "print('   ‚úì Histograms (Distributions)')\n",
        "print('   ‚úì Moving Averages')\n",
        "print('   ‚úì Statistics Cards')\n",
        "print('   ‚úì Dashboard functions')\n",
        "print('   ‚ùå Scatter Plots (REMOVED)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M68MbKKPgOs"
      },
      "source": [
        "## üñ•Ô∏è Screen Functions (Analistic Dashboard & Sync)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VlalUqePjB2"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# Cell 8: Screen Functions (WITHOUT SCATTER ANALYSIS)\n",
        "\n",
        "def sync_screen():\n",
        "    \"\"\"Sync data screen.\"\"\"\n",
        "    msg, count = sync_new_data_from_server()\n",
        "    return msg\n",
        "\n",
        "def dashboard_screen():\n",
        "    \"\"\"Load all data and return comprehensive dashboard (WITHOUT SCATTER).\"\"\"\n",
        "    df = load_data_from_firebase()\n",
        "\n",
        "    if df.empty:\n",
        "        empty_msg = \"<div style='padding: 20px; text-align: center;'>◊ê◊ô◊ü ◊†◊™◊ï◊†◊ô◊ù. ◊ú◊ó◊• ◊¢◊ú Sync Data!</div>\"\n",
        "        return empty_msg, None, None, None, None, None, None, None, None, None, None\n",
        "\n",
        "    # Generate all visualizations (WITHOUT SCATTER)\n",
        "    kpi = create_kpi_cards(df)\n",
        "    stats = create_stat_cards_html(df)\n",
        "    ts = create_time_series_plot(df)\n",
        "    corr_card, corr_plot = calculate_correlations(df)\n",
        "    hourly_card, hourly_plot = hourly_patterns(df)\n",
        "    daily_card, daily_plot = daily_patterns(df)\n",
        "    dist_card, dist_plot = distribution_analysis(df)\n",
        "\n",
        "    return kpi, stats, ts, corr_card, corr_plot, hourly_card, hourly_plot, daily_card, daily_plot, dist_card, dist_plot\n",
        "\n",
        "def dashboard_moving_avg(variable):\n",
        "    \"\"\"Generate moving average plot for selected variable.\"\"\"\n",
        "    df = load_data_from_firebase()\n",
        "    if df.empty:\n",
        "        return None, \"◊ê◊ô◊ü ◊†◊™◊ï◊†◊ô◊ù\"\n",
        "    ma_card, ma_plot = time_series_decomposition(df, variable)\n",
        "    return ma_card, ma_plot\n",
        "\n",
        "print('‚úÖ All screen functions loaded!')\n",
        "print('   üìä Dashboard (without scatter)')\n",
        "print('   üìâ Moving Averages')\n",
        "print('   üîÑ Data Sync')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcqPbzgaOxyl"
      },
      "source": [
        "‚úÖ APP BUILDER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXglJeFNO2rU"
      },
      "outputs": [],
      "source": [
        "def build_app():\n",
        "    with gr.Blocks(css=CUSTOM_CSS, title=\"Cloud Garden - IoT & AI\") as demo:\n",
        "        gr.Markdown(\"# üåø Cloud Garden - IoT & AI\")\n",
        "\n",
        "        rewards_tab_ref = None\n",
        "        rewards_outputs = None\n",
        "\n",
        "        with gr.Tabs():\n",
        "            for tab_name, tab_builder in TABS:\n",
        "                if tab_name.startswith(\"üéÆ\"):\n",
        "                    with gr.Tab(tab_name) as rewards_tab_ref:\n",
        "                        rewards_outputs = tab_builder()\n",
        "                else:\n",
        "                    with gr.Tab(tab_name):\n",
        "                        tab_builder()\n",
        "\n",
        "        # auto-refresh rewards on load + on tab select\n",
        "        if rewards_tab_ref and rewards_outputs:\n",
        "            points_box, spins_box, missions_md, coupons_txt = rewards_outputs\n",
        "\n",
        "            demo.load(fn=rewards_refresh, outputs=[points_box, spins_box, missions_md, coupons_txt])\n",
        "            rewards_tab_ref.select(fn=rewards_refresh, outputs=[points_box, spins_box, missions_md, coupons_txt])\n",
        "\n",
        "    return demo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtxmPPB0O17q"
      },
      "source": [
        "‚úÖ LAUNCH (ONLY ONE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bg5JT_i5O7mq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "07fbd565-769a-4b4c-e0c6-acca80aad27d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://26b6556a2e27f2f454.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://26b6556a2e27f2f454.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    app = build_app()\n",
        "    app.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}